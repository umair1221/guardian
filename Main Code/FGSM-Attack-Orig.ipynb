{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9eaae14d-3350-4c1a-a454-f0f7319bb822",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "392a2f0b-7eb8-4c68-9300-d582bd194b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import torch\n",
    "import random\n",
    "import network\n",
    "import argparse\n",
    "import platform\n",
    "import ivtmetrics # You must \"pip install ivtmetrics\" to use\n",
    "import dataloader\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import numpy as np\n",
    "# import lpips\n",
    "import piq\n",
    "from torchvision.utils import save_image\n",
    "from torchvision.utils import save_image\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a18d72e-37a8-4c0b-baf5-323eb953dd0a",
   "metadata": {},
   "source": [
    "# Argument Parser\n",
    "\n",
    "## In case of running using cmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87d0903c-107a-41d8-ad36-21e8e6434a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% @args parsing\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument('--model', type=str, default='rendezvous', choices=['rendezvous'], help='Model name?')\n",
    "parser.add_argument('--version', type=int, default=0,  help='Model version control (for keeping several versions)') \n",
    "parser.add_argument('--hr_output', action='store_true', help='Whether to use higher resolution output (32x56) or not (8x14). Default: False')\n",
    "parser.add_argument('--use_ln', action='store_true', help='Whether to use layer norm or batch norm in AddNorm() function. Default: False')\n",
    "parser.add_argument('--decoder_layer', type=int, default=8, help='Number of MHMA layers ') \n",
    "# job\n",
    "parser.add_argument('-t', '--train', action='store_true', help='to train.')\n",
    "parser.add_argument('-e', '--test',  action='store_true', help='to test')\n",
    "parser.add_argument('--val_interval', type=int, default=1,  help='(for hp tuning). Epoch interval to evaluate on validation data. set -1 for only after final epoch, or a number higher than the total epochs to not validate.')\n",
    "# data\n",
    "parser.add_argument('--data_dir', type=str, default='/path/to/dataset', help='path to dataset?')\n",
    "parser.add_argument('--dataset_variant', type=str, default='cholect45-crossval', choices=['cholect50', 'cholect45', 'cholect50-challenge', 'cholect50-crossval', 'cholect45-crossval'], help='Variant of the dataset to use')\n",
    "parser.add_argument('-k', '--kfold', type=int, default=1,  choices=[1,2,3,4,5,], help='The test split in k-fold cross-validation')\n",
    "parser.add_argument('--image_width', type=int, default=448, help='Image width ')  \n",
    "parser.add_argument('--image_height', type=int, default=256, help='Image height ')  \n",
    "parser.add_argument('--image_channel', type=int, default=3, help='Image channels ')  \n",
    "parser.add_argument('--num_tool_classes', type=int, default=6, help='Number of tool categories')\n",
    "parser.add_argument('--num_verb_classes', type=int, default=10, help='Number of verb categories')\n",
    "parser.add_argument('--num_target_classes', type=int, default=15, help='Number of target categories')\n",
    "parser.add_argument('--num_triplet_classes', type=int, default=100, help='Number of triplet categories')\n",
    "parser.add_argument('--augmentation_list', type=str, nargs='*', default=['original', 'vflip', 'hflip', 'contrast', 'rot90'], help='List augumentation styles (see dataloader.py for list of supported styles).')\n",
    "# hp\n",
    "parser.add_argument('-b', '--batch', type=int, default=32,  help='The size of sample training batch')\n",
    "parser.add_argument('--epochs', type=int, default=100,  help='How many training epochs?')\n",
    "parser.add_argument('-w', '--warmups', type=int, nargs='+', default=[9,18,58], help='List warmup epochs for tool, verb-target, triplet respectively')\n",
    "parser.add_argument('-l', '--initial_learning_rates', type=float, nargs='+', default=[0.01, 0.01, 0.01], help='List learning rates for tool, verb-target, triplet respectively')\n",
    "parser.add_argument('--weight_decay', type=float, default=1e-5,  help='L2 regularization weight decay constant')\n",
    "parser.add_argument('--decay_steps', type=int, default=10,  help='Step to exponentially decay')\n",
    "parser.add_argument('--decay_rate', type=float, default=0.99,  help='Learning rates weight decay rate')\n",
    "parser.add_argument('--momentum', type=float, default=0.95,  help=\"Optimizer's momentum\")\n",
    "parser.add_argument('--power', type=float, default=0.1,  help='Learning rates weight decay power')\n",
    "# weights\n",
    "parser.add_argument('--pretrain_dir', type=str, default='', help='path to pretrain_weight?')\n",
    "parser.add_argument('--test_ckpt', type=str, default=None, help='path to model weight for testing')\n",
    "# device\n",
    "parser.add_argument('--gpu', type=str, default=\"0\",  help='The gpu device to use. To use multiple gpu put all the device ids comma-separated, e.g: \"0,1,2\" ')\n",
    "FLAGS, unparsed = parser.parse_known_args()\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c479dfe0-a712-4ed5-ba76-cbe948f3f4de",
   "metadata": {},
   "source": [
    "# Parameters Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3a6c2e5a-de5a-4caf-af2b-5b033622fe0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuring network ...\n"
     ]
    }
   ],
   "source": [
    "#%% @params definitions\n",
    "is_train        = FLAGS.train\n",
    "is_test         = FLAGS.test\n",
    "dataset_variant = FLAGS.dataset_variant\n",
    "data_dir        = FLAGS.data_dir\n",
    "kfold           = FLAGS.kfold if \"crossval\" in dataset_variant else 0\n",
    "version         = FLAGS.version\n",
    "hr_output       = FLAGS.hr_output\n",
    "use_ln          = FLAGS.use_ln\n",
    "batch_size      = FLAGS.batch\n",
    "pretrain_dir    = FLAGS.pretrain_dir\n",
    "test_ckpt       = FLAGS.test_ckpt\n",
    "weight_decay    = FLAGS.weight_decay\n",
    "learning_rates  = FLAGS.initial_learning_rates\n",
    "warmups         = FLAGS.warmups\n",
    "decay_steps     = FLAGS.decay_steps\n",
    "decay_rate      = FLAGS.decay_rate\n",
    "power           = FLAGS.power\n",
    "momentum        = FLAGS.momentum\n",
    "epochs          = FLAGS.epochs\n",
    "gpu             = FLAGS.gpu\n",
    "image_height    = FLAGS.image_height\n",
    "image_width     = FLAGS.image_width\n",
    "image_channel   = FLAGS.image_channel\n",
    "num_triplet     = FLAGS.num_triplet_classes\n",
    "num_tool        = FLAGS.num_tool_classes\n",
    "num_verb        = FLAGS.num_verb_classes\n",
    "num_target      = FLAGS.num_target_classes\n",
    "val_interval    = FLAGS.epochs-1 if FLAGS.val_interval==-1 else FLAGS.val_interval\n",
    "set_chlg_eval   = True if \"challenge\" in dataset_variant else False # To observe challenge evaluation protocol\n",
    "gpu             = \",\".join(str(FLAGS.gpu).split(\",\"))\n",
    "decodelayer     = FLAGS.decoder_layer\n",
    "addnorm         = \"layer\" if use_ln else \"batch\"\n",
    "modelsize       = \"high\" if hr_output else \"low\"\n",
    "FLAGS.multigpu  = len(gpu) > 1  # not yet implemented !\n",
    "mheaders        = [\"\",\"l\", \"cholect\", \"k\"]\n",
    "margs           = [FLAGS.model, decodelayer, dataset_variant, kfold]\n",
    "wheaders        = [\"norm\", \"res\"]\n",
    "wargs           = [addnorm, modelsize]\n",
    "modelname       = \"_\".join([\"{}{}\".format(x,y) for x,y in zip(mheaders, margs) if len(str(y))])+\"_\"+\\\n",
    "                  \"_\".join([\"{}{}\".format(x,y) for x,y in zip(wargs, wheaders) if len(str(x))])\n",
    "model_dir       = \"./__checkpoint__/run_{}\".format(version)\n",
    "\n",
    "if not os.path.exists(model_dir): os.makedirs(model_dir)\n",
    "resume_ckpt     = None\n",
    "ckpt_path       = os.path.join(model_dir, '{}.pth'.format(modelname))\n",
    "logfile         = os.path.join(model_dir, '{}.log'.format(modelname))\n",
    "data_augmentations      = FLAGS.augmentation_list \n",
    "iterable_augmentations  = []\n",
    "print(\"Configuring network ...\")\n",
    "\n",
    "#%% @functions (helpers)\n",
    "def assign_gpu(gpu=None):  \n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu) \n",
    "    os.environ['TF_ENABLE_WINOGRAD_NONFUSED'] = '1' \n",
    "    \n",
    "\n",
    "def get_weight_balancing(case='cholect50'):\n",
    "    # 50:   cholecT50, data splits as used in rendezvous paper\n",
    "    # 50ch: cholecT50, data splits as used in CholecTriplet challenge\n",
    "    # 45cv: cholecT45, official data splits (cross-val)\n",
    "    # 50cv: cholecT50, official data splits (cross-val)\n",
    "    switcher = {\n",
    "        'cholect50': {\n",
    "            'tool'  :   [0.08084519, 0.81435289, 0.10459284, 2.55976864, 1.630372490, 1.29528455],\n",
    "            'verb'  :   [0.31956735, 0.07252306, 0.08111481, 0.81137309, 1.302895320, 2.12264151, 1.54109589, 8.86363636, 12.13692946, 0.40462028],\n",
    "            'target':   [0.06246232, 1.00000000, 0.34266478, 0.84750219, 14.80102041, 8.73795181, 1.52845100, 5.74455446, 0.285756500, 12.72368421, 0.6250808,  3.85771277, 6.95683453, 0.84923888, 0.40130032]\n",
    "        },\n",
    "        'cholect50-challenge': {\n",
    "            'tool':     [0.08495163, 0.88782288, 0.11259564, 2.61948830, 1.784866470, 1.144624170],\n",
    "            'verb':     [0.39862805, 0.06981640, 0.08332925, 0.81876204, 1.415868390, 2.269359150, 1.28428410, 7.35822511, 18.67857143, 0.45704490],\n",
    "            'target':   [0.07333818, 0.87139287, 0.42853950, 1.00000000, 17.67281106, 13.94545455, 1.44880997, 6.04889590, 0.326188650, 16.82017544, 0.63577586, 6.79964539, 6.19547658, 0.96284208, 0.51559559]\n",
    "        },\n",
    "        'cholect45-crossval': {\n",
    "            1: {\n",
    "                'tool':     [0.08165644, 0.91226868, 0.10674758, 2.85418156, 1.60554885, 1.10640067],\n",
    "                'verb':     [0.37870137, 0.06836869, 0.07931255, 0.84780024, 1.21880342, 2.52836879, 1.30765704, 6.88888889, 17.07784431, 0.45241117],\n",
    "                'target':   [0.07149629, 1.0, 0.41013597, 0.90458015, 13.06299213, 12.06545455, 1.5213205, 5.04255319, 0.35808332, 45.45205479, 0.67493897, 7.04458599, 9.14049587, 0.97330595, 0.52633249]\n",
    "                },\n",
    "            2: {\n",
    "                'tool':     [0.0854156, 0.89535362, 0.10995253, 2.74936869, 1.78264429, 1.13234529],\n",
    "                'verb':     [0.36346863, 0.06771776, 0.07893261, 0.82842725, 1.33892161, 2.13049748, 1.26120359, 5.72674419, 19.7, 0.43189126],\n",
    "                'target':   [0.07530655, 0.97961957, 0.4325135, 0.99393438, 15.5387931, 14.5951417, 1.53862569, 6.01836394, 0.35184462, 15.81140351, 0.709506, 5.79581994, 8.08295964, 1.0, 0.52689272]\n",
    "            },\n",
    "            3: {\n",
    "                \"tool\" :   [0.0915228, 0.89714969, 0.12057004, 2.72128174, 1.94092281, 1.12948557],\n",
    "                \"verb\" :   [0.43636862, 0.07558554, 0.0891017, 0.81820519, 1.53645582, 2.31924198, 1.28565657, 6.49387755, 18.28735632, 0.48676763],\n",
    "                \"target\" : [0.06841828, 0.90980736, 0.38826607, 1.0, 14.3640553, 12.9875, 1.25939394, 5.38341969, 0.29060227, 13.67105263, 0.59168565, 6.58985201, 5.72977941, 0.86824513, 0.47682423]\n",
    "\n",
    "            },\n",
    "            4: {\n",
    "                'tool':     [0.08222218, 0.85414117, 0.10948695, 2.50868784, 1.63235867, 1.20593318],\n",
    "                'verb':     [0.41154261, 0.0692142, 0.08427214, 0.79895288, 1.33625219, 2.2624166, 1.35343681, 7.63, 17.84795322, 0.43970609],\n",
    "                'target':   [0.07536126, 0.85398445, 0.4085784, 0.95464422, 15.90497738, 18.5978836, 1.55875831, 5.52672956, 0.33700863, 15.41666667, 0.74755423, 5.4921875, 6.11304348, 1.0, 0.50641118],\n",
    "            },\n",
    "            5: {\n",
    "                'tool':     [0.0804654, 0.92271157, 0.10489631, 2.52302243, 1.60074906, 1.09141982],\n",
    "                'verb':     [0.50710436, 0.06590258, 0.07981184, 0.81538866, 1.29267277, 2.20525568, 1.29699248, 7.32311321, 25.45081967, 0.46733895],\n",
    "                'target':   [0.07119395, 0.87450495, 0.43043372, 0.86465981, 14.01984127, 23.7114094, 1.47577277, 5.81085526, 0.32129865, 22.79354839, 0.63304067, 6.92745098, 5.88833333, 1.0, 0.53175798]\n",
    "            }\n",
    "        },\n",
    "        'cholect50-crossval': {\n",
    "            1:{\n",
    "                'tool':     [0.0828851, 0.8876, 0.10830995, 2.93907285, 1.63884786, 1.14499484],\n",
    "                'verb':     [0.29628942, 0.07366916, 0.08267971, 0.83155428, 1.25402434, 2.38358209, 1.34938741, 7.56872038, 12.98373984, 0.41502079],\n",
    "                'target':   [0.06551745, 1.0, 0.36345711, 0.82434783, 13.06299213, 8.61818182, 1.4017744, 4.62116992, 0.32822238, 45.45205479, 0.67343211, 4.13200498, 8.23325062, 0.88527215, 0.43113306],\n",
    "\n",
    "            },\n",
    "            2:{\n",
    "                'tool':     [0.08586283, 0.87716737, 0.11068887, 2.84210526, 1.81016949, 1.16283571],\n",
    "                'verb':     [0.30072757, 0.07275414, 0.08350168, 0.80694143, 1.39209979, 2.22754491, 1.31448763, 6.38931298, 13.89211618, 0.39397505],\n",
    "                'target':   [0.07056703, 1.0, 0.39451115, 0.91977006, 15.86206897, 9.68421053, 1.44483706, 5.44378698, 0.31858714, 16.14035088, 0.7238395, 4.20571429, 7.98264642, 0.91360477, 0.43304307],\n",
    "            },\n",
    "            3:{\n",
    "            'tool':      [0.09225068, 0.87856006, 0.12195811, 2.82669323, 1.97710987, 1.1603972],\n",
    "                'verb':     [0.34285159, 0.08049804, 0.0928239, 0.80685714, 1.56125608, 2.23984772, 1.31471136, 7.08835341, 12.17241379, 0.43180428],\n",
    "                'target':   [0.06919395, 1.0, 0.37532866, 0.9830703, 15.78801843, 8.99212598, 1.27597765, 5.36990596, 0.29177312, 15.02631579, 0.64935557, 5.08308605, 5.86643836, 0.86580743, 0.41908257], \n",
    "            },\n",
    "            4:{\n",
    "                'tool':     [0.08247885, 0.83095539, 0.11050268, 2.58193042, 1.64497676, 1.25538881],\n",
    "                'verb':     [0.31890981, 0.07380354, 0.08804592, 0.79094077, 1.35928144, 2.17017208, 1.42947103, 8.34558824, 13.19767442, 0.40666428],\n",
    "                'target':   [0.07777646, 0.95894072, 0.41993829, 0.95592153, 17.85972851, 12.49050633, 1.65701092, 5.74526929, 0.33763901, 17.31140351, 0.83747083, 3.95490982, 6.57833333, 1.0, 0.47139615],\n",
    "            },\n",
    "            5:{\n",
    "                'tool':     [0.07891691, 0.89878025, 0.10267677, 2.53805556, 1.60636428, 1.12691169],\n",
    "                'verb':     [0.36420961, 0.06825313, 0.08060635, 0.80956984, 1.30757221, 2.09375, 1.33625848, 7.9009434, 14.1350211, 0.41429631],\n",
    "                'target':   [0.07300329, 0.97128713, 0.42084942, 0.8829883, 15.57142857, 19.42574257, 1.56521739, 5.86547085, 0.32732733, 25.31612903, 0.70171674, 4.55220418, 6.13125, 1.0, 0.48528321],\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    return switcher.get(case)\n",
    "     "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a2ed47b-0c74-4f22-b693-3f5f74514db2",
   "metadata": {},
   "source": [
    "# Loading and Building Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b346c61f-cdd8-46df-a26b-53b730a700e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/umairnawaz/.conda/envs/myenv/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/umairnawaz/.conda/envs/myenv/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model built ...\n"
     ]
    }
   ],
   "source": [
    "# Path to model checkpoint\n",
    "test_ckpt = 'weights/rendezvous_l8_cholectcholect45-crossval_k1_batchnorm_lowres_180.pth'\n",
    "\n",
    "# Load base structure model\n",
    "model = network.Rendezvous('resnet18', hr_output=hr_output, use_ln=use_ln).cuda()\n",
    "pytorch_total_params = sum(p.numel() for p in model.parameters())\n",
    "pytorch_train_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "#%% performance tracker for hp tuning\n",
    "benchmark   = torch.nn.Parameter(torch.tensor([0.0]), requires_grad=False)\n",
    "print(\"Model built ...\")\n",
    "\n",
    "# Load the checkpoint of the trained model\n",
    "if os.path.exists(test_ckpt):\n",
    "    model.load_state_dict(torch.load(test_ckpt) ,  strict=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99121f68-aab1-41a4-b965-77fe339897f3",
   "metadata": {},
   "source": [
    "# Define Loss, Activation, and mAP Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6f56a35e-c1cf-4d83-98e2-7c734c433445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics built ...\n"
     ]
    }
   ],
   "source": [
    "# Or constant weights from average of the random sampling of the dataset: we found this to produce better result.\n",
    "tool_weight     = [0.93487068, 0.94234964, 0.93487068, 1.18448115, 1.02368339, 0.97974447]\n",
    "verb_weight     = [0.60002400, 0.60002400, 0.60002400, 0.61682467, 0.67082683, 0.80163207, 0.70562823, 2.11208448, 2.69230769, 0.60062402]\n",
    "target_weight   = [0.49752894, 0.52041527, 0.49752894, 0.51394739, 2.71899565, 1.75577963, 0.58509403, 1.25228034, 0.49752894, 2.42993134, 0.49802647, 0.87266576, 1.36074165, 0.50150917, 0.49802647]\n",
    "\n",
    "\n",
    "#%% Loss\n",
    "activation  = nn.Sigmoid()\n",
    "loss_fn_i   = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(tool_weight).cuda())\n",
    "loss_fn_v   = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(verb_weight).cuda())\n",
    "loss_fn_t   = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(target_weight).cuda())\n",
    "loss_fn_ivt = nn.BCEWithLogitsLoss()\n",
    "\n",
    "#Monkey patches\n",
    "np.float = float    \n",
    "np.int = int\n",
    "np.object = object\n",
    "np.bool = bool  \n",
    "\n",
    "#%% evaluation metrics\n",
    "mAP = ivtmetrics.Recognition(100)\n",
    "mAP.reset_global()\n",
    "if not set_chlg_eval:\n",
    "    mAPi = ivtmetrics.Recognition(6)\n",
    "    mAPv = ivtmetrics.Recognition(10)\n",
    "    mAPt = ivtmetrics.Recognition(15)\n",
    "    mAPi.reset_global()\n",
    "    mAPv.reset_global()\n",
    "    mAPt.reset_global()\n",
    "\n",
    "#%% Adversarial metrics\n",
    "mAP_adv = ivtmetrics.Recognition(100)\n",
    "mAP_adv.reset_global()\n",
    "if not set_chlg_eval:\n",
    "    mAPi_adv = ivtmetrics.Recognition(6)\n",
    "    mAPv_adv = ivtmetrics.Recognition(10)\n",
    "    mAPt_adv = ivtmetrics.Recognition(15)\n",
    "    mAPi_adv.reset_global()\n",
    "    mAPv_adv.reset_global()\n",
    "    mAPt_adv.reset_global()\n",
    "print(\"Metrics built ...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cc6fe92-1b2d-49d6-b742-4b1ea06666b4",
   "metadata": {},
   "source": [
    "# Dataset Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aeacc7d1-7acf-41df-929b-8d7d50bc4ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% data loading : variant and split selection (Note: original paper used different augumentation per epoch)\n",
    "data_dir = '/share/sdb/umairnawaz/Data/'\n",
    "dataset_variant= 'cholect45-crossval'\n",
    "dataset = dataloader.CholecT50( \n",
    "            dataset_dir=data_dir, \n",
    "            dataset_variant=dataset_variant,\n",
    "            test_fold=kfold,\n",
    "            augmentation_list=data_augmentations,\n",
    "            )\n",
    "\n",
    "# build dataset\n",
    "train_dataset, val_dataset, test_dataset = dataset.build()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c453d4cd-112c-4acf-9910-241d82a8bc18",
   "metadata": {},
   "source": [
    "# Load only test dataset in dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6c9bb56a-d89c-479d-a29e-b4877cfd973f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded ...\n"
     ]
    }
   ],
   "source": [
    "test_dataloaders = []\n",
    "for video_dataset in test_dataset:\n",
    "    test_dataloader = DataLoader(video_dataset, batch_size=batch_size, shuffle=False, prefetch_factor=3*batch_size, num_workers=3, pin_memory=True, persistent_workers=True, drop_last=False)\n",
    "    test_dataloaders.append(test_dataloader)\n",
    "print(\"Dataset loaded ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3029dfa7-a194-4ffb-a620-7252bf284315",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device to load the model on\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Function to perform FGSM attack\n",
    "def fast_gradient_sign_method(model, x, y, eps=8/255):    \n",
    "\n",
    "    # Original Images\n",
    "    x = x.clone().detach().cuda().requires_grad_(True)\n",
    "    \n",
    "    targeted = False  # Change to True if we have a targeted attack\n",
    "    y_target = None    # Set the target label if it's a targeted attack\n",
    "\n",
    "    # Forward pass\n",
    "    tool, verb, target, triplet = model(x)\n",
    "\n",
    "    # Extracting Logits and CAMs of each category\n",
    "    \n",
    "    cam_i, logit_i  = tool\n",
    "    cam_v, logit_v  = verb\n",
    "    cam_t, logit_t  = target\n",
    "    logit_ivt       = triplet            \n",
    "\n",
    "    # Compute Loss\n",
    "    loss_i          = loss_fn_i(logit_i, y[0].float())\n",
    "    loss_v          = loss_fn_v(logit_v, y[1].float())\n",
    "    loss_t          = loss_fn_t(logit_t, y[2].float())\n",
    "    loss_ivt        = loss_fn_ivt(logit_ivt, y[3].float()) \n",
    "\n",
    "    # Total Loss\n",
    "    loss = (loss_i) + (loss_v) + (loss_t) + loss_ivt \n",
    "\n",
    "    # Find the gradient\n",
    "    grad = torch.autograd.grad(\n",
    "        loss, x, retain_graph=False, create_graph=False, allow_unused=True\n",
    "    )[0]\n",
    "\n",
    "    # Update adversarial images\n",
    "    if grad is not None:\n",
    "        # print(\"Varifying Gradient\")\n",
    "        x_adv = x + (eps * grad.sign())\n",
    "        x_adv = torch.clamp(x_adv, min=0, max=1).detach()\n",
    "\n",
    "    return x_adv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34495225",
   "metadata": {},
   "source": [
    "## Spatial Smoothing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1f3e8f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/umairnawaz/.conda/envs/myenv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from typing import Optional, Tuple\n",
    "\n",
    "import numpy as np\n",
    "from scipy.ndimage import median_filter\n",
    "\n",
    "from art.utils import CLIP_VALUES_TYPE\n",
    "from art.defences.preprocessor.preprocessor import Preprocessor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7cf38934",
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [\"window_size\", \"channels_first\", \"clip_values\"]\n",
    "\n",
    "def spatialSmoothing(x, y=None):\n",
    "    window_size = 3  # Fixed: Removed the comma to define it as an int, not a tuple\n",
    "    channels_first = False\n",
    "    clip_values = None\n",
    "\n",
    "    x_ndim = x.ndim\n",
    "    # print(\"The dimensions are: \", x_ndim)\n",
    "    if x_ndim not in [4, 5]:\n",
    "        raise ValueError(\"Unrecognized input dimension. Spatial smoothing can only be applied to image and video data.\")\n",
    "\n",
    "    # get channel index\n",
    "    channel_index = 1 if channels_first else x_ndim - 1\n",
    "\n",
    "    filter_size = [window_size] * (x_ndim - 2)  # Adjusted for the spatial dimensions only\n",
    "    filter_size = [1] + filter_size + [1]  # Adjust for batch and channel dimensions\n",
    "    print(\"Filter size: \", filter_size)\n",
    "\n",
    "    # print(\"Original tensor shape: \", x.shape)\n",
    "    if x.is_cuda:\n",
    "        x = x.cpu()  # Ensure tensor is on CPU\n",
    "    x = x.permute(0, 2, 3, 1).numpy()  # Rearrange and convert to NumPy\n",
    "    # print(\"After permute and conversion shape: \", x.shape)\n",
    "    \n",
    "    result = median_filter(x, size=tuple(filter_size), mode=\"reflect\")\n",
    "\n",
    "    if clip_values is not None:\n",
    "        np.clip(result, clip_values[0], clip_values[1], out=result)\n",
    "\n",
    "    \n",
    "    result_tensor = torch.from_numpy(result)\n",
    "    result_tensor = result_tensor.permute(0, 3, 1, 2)\n",
    "    # Move the tensor to GPU if your original tensor was on a GPU\n",
    "    if torch.cuda.is_available():\n",
    "        result_tensor = result_tensor.to('cuda')\n",
    "\n",
    "    return result_tensor, y\n",
    "\n",
    "def _check_params(self) -> None:\n",
    "    if not (isinstance(self.window_size, int) and self.window_size > 0):\n",
    "        raise ValueError(\"Sliding window size must be a positive integer.\")\n",
    "\n",
    "    if self.clip_values is not None and len(self.clip_values) != 2:\n",
    "        raise ValueError(\"'clip_values' should be a tuple of 2 floats or arrays containing the allowed data range.\")\n",
    "\n",
    "    if self.clip_values is not None and np.array(self.clip_values[0] >= self.clip_values[1]).any():\n",
    "        raise ValueError(\"Invalid 'clip_values': min >= max.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b0b4fe3",
   "metadata": {},
   "source": [
    "## Pixel Defend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3ca93bc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "\n",
    "import logging\n",
    "from typing import Optional, Tuple, TYPE_CHECKING\n",
    "\n",
    "import numpy as np\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from art.config import ART_NUMPY_DTYPE\n",
    "from art.defences.preprocessor.preprocessor import Preprocessor\n",
    "\n",
    "if TYPE_CHECKING:\n",
    "    from art.utils import CLIP_VALUES_TYPE, CLASSIFIER_NEURALNETWORK_TYPE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e4d8f68a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pixelDefend(x, y = None):\n",
    "    clip_values = (0.0, 1.0),\n",
    "    eps= 16,\n",
    "    pixel_cnn = None,\n",
    "    batch_size = 128,\n",
    "    apply_fit = False,\n",
    "    apply_predict = True,\n",
    "    verbose = False,\n",
    "    \"\"\"\n",
    "    Apply pixel defence to sample `x`.\n",
    "\n",
    "    :param x: Sample to defense with shape `(batch_size, width, height, depth)`. `x` values are expected to be in\n",
    "            the data range [0, 1].\n",
    "    :param y: Labels of the sample `x`. This function does not affect them in any way.\n",
    "    :return: Purified sample.\n",
    "    \"\"\"\n",
    "    # Convert into `uint8`\n",
    "    original_shape = x.shape\n",
    "    if pixel_cnn is not None:\n",
    "        activations = pixel_cnn.get_activations(x, layer=-1, batch_size=batch_size)\n",
    "        if isinstance(activations, np.ndarray):\n",
    "            probs = activations.reshape((x.shape[0], -1, 256))\n",
    "        else:\n",
    "            raise ValueError(\"Activations are None.\")\n",
    "    else:\n",
    "        raise ValueError(\"No model received for `pixel_cnn`.\")\n",
    "\n",
    "    x = x * 255\n",
    "    x = x.astype(\"uint8\")\n",
    "    x = x.reshape((x.shape[0], -1))\n",
    "\n",
    "    # Start defence one image at a time\n",
    "    for i, x_i in enumerate(tqdm(x, desc=\"PixelDefend\", disable=not verbose)):\n",
    "        for feat_index in range(x.shape[1]):\n",
    "            # Setup the search space\n",
    "            f_probs = probs[i, feat_index, :]\n",
    "            f_range = range(\n",
    "                int(max(x_i[feat_index] - eps, 0)),\n",
    "                int(min(x_i[feat_index] + eps, 255) + 1),\n",
    "            )\n",
    "\n",
    "            # Look in the search space\n",
    "            best_prob = -1\n",
    "            best_idx = -1\n",
    "            for idx in f_range:\n",
    "                if f_probs[idx] > best_prob:\n",
    "                    best_prob = f_probs[idx]\n",
    "                    best_idx = idx\n",
    "\n",
    "            # Update result\n",
    "            x_i[feat_index] = best_idx\n",
    "\n",
    "        # Update in batch\n",
    "        x[i] = x_i\n",
    "\n",
    "    # Convert to old dtype\n",
    "    x = x / 255.0\n",
    "    x = x.astype(ART_NUMPY_DTYPE).reshape(original_shape)\n",
    "\n",
    "    # Clip to clip_values\n",
    "    x = np.clip(x, clip_values[0], clip_values[1])\n",
    "\n",
    "    return x, y\n",
    "\n",
    "def _check_params(self) -> None:\n",
    "\n",
    "    if not isinstance(self.eps, int) or self.eps < 0 or self.eps > 255:\n",
    "        raise ValueError(\"The defense parameter must be between 0 and 255.\")\n",
    "\n",
    "    from art.estimators.classification.classifier import ClassifierMixin\n",
    "    from art.estimators.estimator import NeuralNetworkMixin\n",
    "\n",
    "    if hasattr(self, \"pixel_cnn\") and not (\n",
    "        isinstance(self.pixel_cnn, ClassifierMixin) and isinstance(self.pixel_cnn, NeuralNetworkMixin)\n",
    "    ):\n",
    "        raise TypeError(\"PixelCNN model must be of type Classifier.\")\n",
    "\n",
    "    if np.array(self.clip_values[0] >= self.clip_values[1]).any():\n",
    "        raise ValueError(\"Invalid `clip_values`: min >= max.\")\n",
    "\n",
    "    if self.clip_values[0] != 0:\n",
    "        raise ValueError(\"`clip_values` min value must be 0.\")\n",
    "\n",
    "    if self.clip_values[1] != 1:\n",
    "        raise ValueError(\"`clip_values` max value must be 1.\")\n",
    "\n",
    "    if self.batch_size <= 0:\n",
    "        raise ValueError(\"The batch size `batch_size` has to be positive.\")\n",
    "\n",
    "    if not isinstance(self.verbose, bool):\n",
    "        raise ValueError(\"The argument `verbose` has to be of type bool.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a60974d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4917ade",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd66677",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "41ddb564-057b-4e5f-ba64-dee7c3a8db28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization layer to normalize the input to expected input of model\n",
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "\n",
    "# Add additional layer to normalize the input to expected input shape of model\n",
    "norm_model = nn.Sequential(\n",
    "            normalize,\n",
    "            model\n",
    "        ).to(device)\n",
    "norm_model = norm_model.eval()\n",
    "\n",
    "# Apply attack on the test dataloader\n",
    "def test_adv(dataloader, activation, final_eval=False):\n",
    "    # Reset the metrics\n",
    "    # Normal model metrics\n",
    "    mAP.reset()  \n",
    "    if final_eval and not set_chlg_eval:\n",
    "        mAPv.reset() \n",
    "        mAPt.reset() \n",
    "        mAPi.reset()\n",
    "    \n",
    "    # Adversarial Metrics\n",
    "    mAP_adv.reset()  \n",
    "    if final_eval and not set_chlg_eval:\n",
    "        mAPv_adv.reset() \n",
    "        mAPt_adv.reset() \n",
    "        mAPi_adv.reset()\n",
    "\n",
    "    \n",
    "    print(\"DataLoader Started:\")\n",
    "    for batch, (img, (y1, y2, y3, y4)) in enumerate(dataloader):\n",
    "        # Extract data in form of batches\n",
    "        img, y1, y2, y3, y4 = img.cuda(), y1.cuda(), y2.cuda(), y3.cuda(), y4.cuda()\n",
    "        \n",
    "        \n",
    "        #################### Normal Testing #####################\n",
    "        # Predictions of the model on clean images\n",
    "        tool, verb, target, triplet = norm_model(img)\n",
    "\n",
    "        # Final Evaluation \n",
    "        if final_eval:\n",
    "            # Get logits and CAMs for each individual category\n",
    "            cam_i, logit_i = tool\n",
    "            cam_v, logit_v = verb\n",
    "            cam_t, logit_t = target\n",
    "\n",
    "            # Update the mAP metrics for each prediction of clean images\n",
    "            mAPi.update(y1.float().detach().cpu(), activation(logit_i).detach().cpu()) # Log metrics \n",
    "            mAPv.update(y2.float().detach().cpu(), activation(logit_v).detach().cpu()) # Log metrics \n",
    "            mAPt.update(y3.float().detach().cpu(), activation(logit_t).detach().cpu()) # Log metrics \n",
    "        mAP.update(y4.float().detach().cpu(), activation(triplet).detach().cpu()) # Log metrics \n",
    "\n",
    "\n",
    "        ############# Adversarial Attack Started ##############\n",
    "\n",
    "        # Adversarial images obtained from FGSM\n",
    "        adversarial_example = fast_gradient_sign_method(norm_model, img, (y1, y2, y3, y4), eps)\n",
    "\n",
    "        # Save the clean and adversarial images\n",
    "        # for i , img_adv in enumerate(adversarial_example):\n",
    "        #     save_image(img[i], f'Images-Attack/Clean/img{i}-{batch}.png')\n",
    "        #     save_image(img_adv, f'Images-Attack/Adv/img-adv{i}-{batch}.png')\n",
    "\n",
    "        #### Finding Metrics for Image Quality ####\n",
    "\n",
    "        adversarial_example , y4 = spatialSmoothing(adversarial_example.cpu() , y4.cpu())\n",
    "        print(img)\n",
    "        print(adversarial_example)\n",
    "\n",
    "        print(k)\n",
    "\n",
    "        # adversarial_example , y4 = adversarial_example.cuda() , y4.cuda()\n",
    "\n",
    "        psnr_values_list.append(piq.psnr(adversarial_example, img).item())\n",
    "        ssim_values_list.append(piq.ssim(adversarial_example, img).item())\n",
    "        lpips_values_list.append(lpips(2*adversarial_example-1, 2*img-1).item())\n",
    "\n",
    "        ######################## Adversarial Testing ########################\n",
    "        \n",
    "        # Testing the attacked images by the model\n",
    "        tool_adv, verb_adv, target_adv, triplet_adv = norm_model(adversarial_example)\n",
    "        \n",
    "        if final_eval:\n",
    "            # Update the mAP metrics for each prediction of adversarial images using logits\n",
    "            \n",
    "            cam_i, logit_i_adv = tool_adv\n",
    "            cam_v, logit_v_adv = verb_adv\n",
    "            cam_t, logit_t_adv = target_adv\n",
    "            mAPi_adv.update(y1.float().detach().cpu(), activation(logit_i_adv).detach().cpu()) # Log metrics \n",
    "            mAPv_adv.update(y2.float().detach().cpu(), activation(logit_v_adv).detach().cpu()) # Log metrics \n",
    "            mAPt_adv.update(y3.float().detach().cpu(), activation(logit_t_adv).detach().cpu()) # Log metrics \n",
    "        mAP_adv.update(y4.float().detach().cpu(), activation(triplet_adv).detach().cpu()) # Log metrics \n",
    "\n",
    "    # End the update of each metric\n",
    "    if final_eval:\n",
    "        mAPv.video_end()\n",
    "        mAPt.video_end()\n",
    "        mAPi.video_end()\n",
    "        \n",
    "    if final_eval:\n",
    "        mAPv_adv.video_end()\n",
    "        mAPt_adv.video_end()\n",
    "        mAPi_adv.video_end()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a068fbc-0ad1-4615-a76f-32f5c6a85934",
   "metadata": {},
   "source": [
    "# Main function for applying attack"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7a541c24-423d-42ec-81ac-32bc2cf33fd0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment started ...\n",
      "   logging outputs to:  weights/Logs/FGSM-Attack-SS.log\n",
      "DataLoader Started:\n",
      "Filter size:  [1, 3, 3, 1]\n",
      "tensor([[[[0.0471, 0.0471, 0.0471,  ..., 0.0549, 0.0549, 0.0549],\n",
      "          [0.0471, 0.0471, 0.0471,  ..., 0.0549, 0.0549, 0.0549],\n",
      "          [0.0471, 0.0471, 0.0471,  ..., 0.0549, 0.0549, 0.0549],\n",
      "          ...,\n",
      "          [0.0471, 0.0471, 0.0471,  ..., 0.0549, 0.0549, 0.0549],\n",
      "          [0.0549, 0.0549, 0.0549,  ..., 0.0549, 0.0549, 0.0549],\n",
      "          [0.0549, 0.0549, 0.0549,  ..., 0.0549, 0.0549, 0.0549]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.0471, 0.0471, 0.0471,  ..., 0.0471, 0.0471, 0.0471],\n",
      "          [0.0471, 0.0471, 0.0471,  ..., 0.0510, 0.0510, 0.0510],\n",
      "          [0.0471, 0.0471, 0.0471,  ..., 0.0471, 0.0471, 0.0471],\n",
      "          ...,\n",
      "          [0.0471, 0.0471, 0.0471,  ..., 0.0549, 0.0549, 0.0549],\n",
      "          [0.0549, 0.0549, 0.0549,  ..., 0.0549, 0.0549, 0.0549],\n",
      "          [0.0549, 0.0549, 0.0549,  ..., 0.0549, 0.0549, 0.0549]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.0471, 0.0471, 0.0471,  ..., 0.0549, 0.0549, 0.0549],\n",
      "          [0.0471, 0.0471, 0.0471,  ..., 0.0549, 0.0549, 0.0549],\n",
      "          [0.0471, 0.0471, 0.0471,  ..., 0.0549, 0.0549, 0.0549],\n",
      "          ...,\n",
      "          [0.0549, 0.0549, 0.0549,  ..., 0.0549, 0.0549, 0.0549],\n",
      "          [0.0549, 0.0549, 0.0549,  ..., 0.0549, 0.0549, 0.0549],\n",
      "          [0.0549, 0.0549, 0.0549,  ..., 0.0549, 0.0549, 0.0549]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.0471, 0.0471, 0.0471,  ..., 0.0471, 0.0471, 0.0471],\n",
      "          [0.0471, 0.0471, 0.0471,  ..., 0.0471, 0.0471, 0.0471],\n",
      "          [0.0471, 0.0471, 0.0471,  ..., 0.0549, 0.0549, 0.0549],\n",
      "          ...,\n",
      "          [0.0471, 0.0471, 0.0471,  ..., 0.0549, 0.0549, 0.0549],\n",
      "          [0.0549, 0.0549, 0.0549,  ..., 0.0549, 0.0549, 0.0549],\n",
      "          [0.0549, 0.0549, 0.0549,  ..., 0.0549, 0.0549, 0.0549]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.0471, 0.0471, 0.0471,  ..., 0.0471, 0.0471, 0.0471],\n",
      "          [0.0471, 0.0471, 0.0471,  ..., 0.0471, 0.0471, 0.0471],\n",
      "          [0.0471, 0.0471, 0.0471,  ..., 0.0549, 0.0549, 0.0549],\n",
      "          ...,\n",
      "          [0.0471, 0.0471, 0.0471,  ..., 0.0549, 0.0549, 0.0549],\n",
      "          [0.0549, 0.0549, 0.0549,  ..., 0.0549, 0.0549, 0.0549],\n",
      "          [0.0549, 0.0549, 0.0549,  ..., 0.0549, 0.0549, 0.0549]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.0471, 0.0471, 0.0471,  ..., 0.0471, 0.0471, 0.0471],\n",
      "          [0.0471, 0.0471, 0.0471,  ..., 0.0471, 0.0471, 0.0471],\n",
      "          [0.0471, 0.0471, 0.0471,  ..., 0.0549, 0.0549, 0.0549],\n",
      "          ...,\n",
      "          [0.0549, 0.0549, 0.0549,  ..., 0.0549, 0.0549, 0.0549],\n",
      "          [0.0549, 0.0549, 0.0549,  ..., 0.0549, 0.0549, 0.0549],\n",
      "          [0.0549, 0.0549, 0.0549,  ..., 0.0549, 0.0549, 0.0549]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]]],\n",
      "       device='cuda:0')\n",
      "tensor([[[[0.0157, 0.0157, 0.0784,  ..., 0.0863, 0.0863, 0.0863],\n",
      "          [0.0784, 0.0784, 0.0784,  ..., 0.0863, 0.0863, 0.0863],\n",
      "          [0.0784, 0.0784, 0.0784,  ..., 0.0863, 0.0863, 0.0863],\n",
      "          ...,\n",
      "          [0.0157, 0.0157, 0.0196,  ..., 0.0863, 0.0863, 0.0863],\n",
      "          [0.0235, 0.0235, 0.0235,  ..., 0.0863, 0.0863, 0.0235],\n",
      "          [0.0863, 0.0235, 0.0235,  ..., 0.0235, 0.0235, 0.0235]],\n",
      "\n",
      "         [[0.0314, 0.0314, 0.0314,  ..., 0.0000, 0.0000, 0.0314],\n",
      "          [0.0314, 0.0314, 0.0314,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0314, 0.0314, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0314, 0.0314, 0.0314,  ..., 0.0314, 0.0314, 0.0314],\n",
      "          [0.0314, 0.0314, 0.0314,  ..., 0.0314, 0.0314, 0.0314],\n",
      "          [0.0314, 0.0314, 0.0314,  ..., 0.0000, 0.0314, 0.0314]],\n",
      "\n",
      "         [[0.0314, 0.0314, 0.0314,  ..., 0.0000, 0.0000, 0.0314],\n",
      "          [0.0314, 0.0314, 0.0314,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0314, 0.0314, 0.0314,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0314, 0.0314, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0314, 0.0314, 0.0314,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.0784, 0.0784, 0.0784,  ..., 0.0784, 0.0784, 0.0157],\n",
      "          [0.0784, 0.0784, 0.0784,  ..., 0.0784, 0.0784, 0.0157],\n",
      "          [0.0784, 0.0784, 0.0784,  ..., 0.0784, 0.0784, 0.0157],\n",
      "          ...,\n",
      "          [0.0235, 0.0235, 0.0784,  ..., 0.0863, 0.0863, 0.0863],\n",
      "          [0.0235, 0.0235, 0.0784,  ..., 0.0863, 0.0863, 0.0863],\n",
      "          [0.0235, 0.0235, 0.0235,  ..., 0.0863, 0.0863, 0.0863]],\n",
      "\n",
      "         [[0.0314, 0.0000, 0.0000,  ..., 0.0314, 0.0000, 0.0000],\n",
      "          [0.0314, 0.0314, 0.0000,  ..., 0.0314, 0.0000, 0.0000],\n",
      "          [0.0314, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0314, 0.0314, 0.0314,  ..., 0.0314, 0.0000, 0.0000],\n",
      "          [0.0314, 0.0314, 0.0314,  ..., 0.0314, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0314, 0.0314,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0314, 0.0314, 0.0314,  ..., 0.0314, 0.0000, 0.0000],\n",
      "          [0.0314, 0.0314, 0.0314,  ..., 0.0314, 0.0000, 0.0000],\n",
      "          [0.0314, 0.0314, 0.0314,  ..., 0.0314, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0314,  ..., 0.0314, 0.0314, 0.0314],\n",
      "          [0.0000, 0.0314, 0.0314,  ..., 0.0314, 0.0314, 0.0314],\n",
      "          [0.0000, 0.0314, 0.0314,  ..., 0.0000, 0.0314, 0.0314]]],\n",
      "\n",
      "\n",
      "        [[[0.0784, 0.0784, 0.0784,  ..., 0.0863, 0.0863, 0.0863],\n",
      "          [0.0784, 0.0784, 0.0784,  ..., 0.0863, 0.0863, 0.0863],\n",
      "          [0.0784, 0.0784, 0.0784,  ..., 0.0863, 0.0863, 0.0863],\n",
      "          ...,\n",
      "          [0.0235, 0.0235, 0.0235,  ..., 0.0235, 0.0235, 0.0235],\n",
      "          [0.0235, 0.0235, 0.0235,  ..., 0.0235, 0.0235, 0.0863],\n",
      "          [0.0235, 0.0235, 0.0235,  ..., 0.0235, 0.0235, 0.0235]],\n",
      "\n",
      "         [[0.0314, 0.0314, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0314, 0.0314, 0.0314,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0314, 0.0314, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0314, 0.0314, 0.0314,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0314, 0.0314, 0.0314,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0314, 0.0314, 0.0314,  ..., 0.0000, 0.0000, 0.0314]],\n",
      "\n",
      "         [[0.0314, 0.0314, 0.0314,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0314, 0.0314, 0.0314,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0314, 0.0314, 0.0314,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0314, 0.0314, 0.0314,  ..., 0.0314, 0.0314, 0.0000],\n",
      "          [0.0314, 0.0314, 0.0314,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0314, 0.0314, 0.0314,  ..., 0.0000, 0.0000, 0.0314]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0.0784, 0.0784, 0.0196,  ..., 0.0157, 0.0157, 0.0157],\n",
      "          [0.0157, 0.0157, 0.0157,  ..., 0.0157, 0.0157, 0.0157],\n",
      "          [0.0196, 0.0157, 0.0196,  ..., 0.0235, 0.0235, 0.0235],\n",
      "          ...,\n",
      "          [0.0157, 0.0157, 0.0235,  ..., 0.0235, 0.0235, 0.0235],\n",
      "          [0.0235, 0.0235, 0.0235,  ..., 0.0235, 0.0235, 0.0235],\n",
      "          [0.0863, 0.0235, 0.0235,  ..., 0.0235, 0.0235, 0.0235]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0314,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0314,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          ...,\n",
      "          [0.0314, 0.0314, 0.0314,  ..., 0.0314, 0.0314, 0.0000],\n",
      "          [0.0314, 0.0314, 0.0314,  ..., 0.0000, 0.0000, 0.0314],\n",
      "          [0.0314, 0.0314, 0.0314,  ..., 0.0000, 0.0000, 0.0314]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000,  ..., 0.0314, 0.0314, 0.0314],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0314, 0.0314, 0.0314],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0314, 0.0314, 0.0314],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0314, 0.0314, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0314],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0314]]],\n",
      "\n",
      "\n",
      "        [[[0.0784, 0.0784, 0.0784,  ..., 0.0157, 0.0157, 0.0157],\n",
      "          [0.0157, 0.0157, 0.0196,  ..., 0.0157, 0.0157, 0.0157],\n",
      "          [0.0157, 0.0157, 0.0196,  ..., 0.0235, 0.0235, 0.0235],\n",
      "          ...,\n",
      "          [0.0157, 0.0157, 0.0784,  ..., 0.0863, 0.0863, 0.0235],\n",
      "          [0.0235, 0.0235, 0.0863,  ..., 0.0863, 0.0863, 0.0235],\n",
      "          [0.0235, 0.0863, 0.0863,  ..., 0.0235, 0.0235, 0.0235]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000,  ..., 0.0314, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0314, 0.0314, 0.0314],\n",
      "          [0.0000, 0.0000, 0.0314,  ..., 0.0314, 0.0314, 0.0314],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0314, 0.0314, 0.0314],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000,  ..., 0.0314, 0.0314, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0314, 0.0314, 0.0314],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0314, 0.0314, 0.0314],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0314, 0.0314, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]]],\n",
      "\n",
      "\n",
      "        [[[0.0157, 0.0157, 0.0157,  ..., 0.0157, 0.0157, 0.0784],\n",
      "          [0.0157, 0.0157, 0.0157,  ..., 0.0157, 0.0235, 0.0784],\n",
      "          [0.0196, 0.0157, 0.0196,  ..., 0.0863, 0.0863, 0.0863],\n",
      "          ...,\n",
      "          [0.0235, 0.0863, 0.0863,  ..., 0.0235, 0.0235, 0.0235],\n",
      "          [0.0235, 0.0863, 0.0863,  ..., 0.0235, 0.0235, 0.0235],\n",
      "          [0.0235, 0.0863, 0.0863,  ..., 0.0235, 0.0235, 0.0235]],\n",
      "\n",
      "         [[0.0314, 0.0314, 0.0314,  ..., 0.0000, 0.0000, 0.0314],\n",
      "          [0.0000, 0.0314, 0.0314,  ..., 0.0000, 0.0000, 0.0314],\n",
      "          [0.0000, 0.0314, 0.0314,  ..., 0.0000, 0.0314, 0.0314],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000]],\n",
      "\n",
      "         [[0.0000, 0.0000, 0.0000,  ..., 0.0314, 0.0314, 0.0314],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0314, 0.0314, 0.0314],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0314, 0.0314, 0.0314],\n",
      "          ...,\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0314, 0.0314, 0.0314],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0314, 0.0314, 0.0314],\n",
      "          [0.0000, 0.0000, 0.0000,  ..., 0.0314, 0.0314, 0.0314]]]],\n",
      "       device='cuda:0')\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'k' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 44\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;66;03m# Load each dataloader iteratively\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m test_dataloader \u001b[38;5;129;01min\u001b[39;00m test_dataloaders:\n\u001b[1;32m     43\u001b[0m     \u001b[38;5;66;03m# Pass the loader to the testing function\u001b[39;00m\n\u001b[0;32m---> 44\u001b[0m     \u001b[43mtest_adv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDone...!. Printing Stats.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# Compute the final update after each dataloader\u001b[39;00m\n\u001b[1;32m     49\u001b[0m \n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m####### Normal Metrics #####\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[23], line 69\u001b[0m, in \u001b[0;36mtest_adv\u001b[0;34m(dataloader, activation, final_eval)\u001b[0m\n\u001b[1;32m     66\u001b[0m \u001b[38;5;28mprint\u001b[39m(img)\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28mprint\u001b[39m(adversarial_example)\n\u001b[0;32m---> 69\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mk\u001b[49m)\n\u001b[1;32m     71\u001b[0m \u001b[38;5;66;03m# adversarial_example , y4 = adversarial_example.cuda() , y4.cuda()\u001b[39;00m\n\u001b[1;32m     73\u001b[0m psnr_values_list\u001b[38;5;241m.\u001b[39mappend(piq\u001b[38;5;241m.\u001b[39mpsnr(adversarial_example, img)\u001b[38;5;241m.\u001b[39mitem())\n",
      "\u001b[0;31mNameError\u001b[0m: name 'k' is not defined"
     ]
    }
   ],
   "source": [
    "################### Perform FGSM attack ##################\n",
    "\n",
    "# Set FGSM parameters\n",
    "eps = 8/255\n",
    "exp_number = 1\n",
    "\n",
    "# Logs Saving File\n",
    "version_adv = 'FGSM-Attack-SS'\n",
    "logfile  = f'weights/Logs/{version_adv}.log'\n",
    "\n",
    "#%% log config\n",
    "header1 = \"** Experiment for FGSM Attack **\"\n",
    "header2 = \"** Eps: {}/255 \\t Exp Number: {} **\".format(int(eps * 255) , exp_number)\n",
    "# header3 = \"** LR Config: Init: {} | Peak: {} | Warmup Epoch: {} | Rise: {} | Decay {} | train params {} | all params {} **\".format([float(f'{sch.get_last_lr()[0]:.6f}') for sch in lr_schedulers], [float(f'{v:.6f}') for v in wp_lr], warmups, power, decay_rate, pytorch_train_params, pytorch_total_params)\n",
    "maxlen  = len(header1)\n",
    "# header1 = \"{}{}{}\".format('*'*((maxlen-len(header1))//2+1), header1, '*'*((maxlen-len(header1))//2+1) )\n",
    "# header2 = \"{}{}{}\".format('*'*((maxlen-len(header2))//2+1), header2, '*'*((maxlen-len(header2))//2+1) )\n",
    "# header3 = \"{}{}{}\".format('*'*((maxlen-len(header3))//2+1), header3, '*'*((maxlen-len(header3))//2+1) )\n",
    "# maxlen  = max(len(header1), len(header2), len(header3))\n",
    "print(\"\\n\\n\\n{}\\n{}\\n{}\\n{}\\n\\n\".format(\"*\"*maxlen, header1, header2, \"*\"*maxlen), file=open(logfile, 'a+'))\n",
    "print(\"Experiment started ...\\n   logging outputs to: \", logfile)\n",
    "\n",
    "# Reset the metrics globally\n",
    "mAP.reset_global()\n",
    "mAP_adv.reset_global()\n",
    "\n",
    "mAPi.reset_global()\n",
    "mAPv.reset_global()\n",
    "mAPt.reset_global()\n",
    "\n",
    "mAPi_adv.reset_global()\n",
    "mAPv_adv.reset_global()\n",
    "mAPt_adv.reset_global()\n",
    "\n",
    "# Create a list to store image quality metrics for each batch\n",
    "psnr_values_list = []\n",
    "ssim_values_list = []\n",
    "lpips_values_list = []\n",
    "lpips = piq.LPIPS()\n",
    "\n",
    "# Load each dataloader iteratively\n",
    "for test_dataloader in test_dataloaders:\n",
    "    # Pass the loader to the testing function\n",
    "    test_adv(test_dataloader, activation, final_eval=True)\n",
    "    \n",
    "    print(\"Done...!. Printing Stats.\")\n",
    "\n",
    "# Compute the final update after each dataloader\n",
    "\n",
    "####### Normal Metrics #####\n",
    "\n",
    "if set_chlg_eval:\n",
    "    mAP_i = mAP.compute_video_AP('i', ignore_null=set_chlg_eval)\n",
    "    mAP_v = mAP.compute_video_AP('v', ignore_null=set_chlg_eval)\n",
    "    mAP_t = mAP.compute_video_AP('t', ignore_null=set_chlg_eval)\n",
    "else:\n",
    "    mAP_i = mAPi.compute_video_AP(ignore_null=set_chlg_eval)\n",
    "    mAP_v = mAPv.compute_video_AP(ignore_null=set_chlg_eval)\n",
    "    mAP_t = mAPt.compute_video_AP(ignore_null=set_chlg_eval)\n",
    "\n",
    "mAP_iv = mAP.compute_video_AP('iv', ignore_null=set_chlg_eval)\n",
    "mAP_it = mAP.compute_video_AP('it', ignore_null=set_chlg_eval)\n",
    "mAP_ivt = mAP.compute_video_AP('ivt', ignore_null=set_chlg_eval) \n",
    "\n",
    "####### Adversarial Metrics #####\n",
    "\n",
    "if set_chlg_eval:\n",
    "    mAP_i_adv = mAP_adv.compute_video_AP('i', ignore_null=set_chlg_eval)\n",
    "    mAP_v_adv = mAP_adv.compute_video_AP('v', ignore_null=set_chlg_eval)\n",
    "    mAP_t_adv = mAP_adv.compute_video_AP('t', ignore_null=set_chlg_eval)\n",
    "else:\n",
    "    mAP_i_adv = mAPi_adv.compute_video_AP(ignore_null=set_chlg_eval)\n",
    "    mAP_v_adv = mAPv_adv.compute_video_AP(ignore_null=set_chlg_eval)\n",
    "    mAP_t_adv = mAPt_adv.compute_video_AP(ignore_null=set_chlg_eval)\n",
    "\n",
    "mAP_iv_adv = mAP_adv.compute_video_AP('iv', ignore_null=set_chlg_eval)\n",
    "mAP_it_adv = mAP_adv.compute_video_AP('it', ignore_null=set_chlg_eval)\n",
    "mAP_ivt_adv = mAP_adv.compute_video_AP('ivt', ignore_null=set_chlg_eval) \n",
    "\n",
    "# Print the results into the logging file\n",
    "\n",
    "######### Printing Baseline Model Stats #########\n",
    "\n",
    "print('-'*50, file=open(logfile, 'a+'))\n",
    "print('Test Results\\nPer-category AP: ', file=open(logfile, 'a+'))\n",
    "print('-'*50, file=open(logfile, 'a+'))\n",
    "print(f'Mean AP:  I  |  V  |  T  |  IV  |  IT  |  IVT ', file=open(logfile, 'a+'))\n",
    "print(f':::::: : {mAP_i[\"mAP\"]:.4f} | {mAP_v[\"mAP\"]:.4f} | {mAP_t[\"mAP\"]:.4f} | {mAP_iv[\"mAP\"]:.4f} | {mAP_it[\"mAP\"]:.4f} | {mAP_ivt[\"mAP\"]:.4f} ', file=open(logfile, 'a+'))\n",
    "print('='*50, file=open(logfile, 'a+'))\n",
    "print(\"Test results saved @ \", logfile)\n",
    "\n",
    "######### Printing Adversarial Stats #########\n",
    "\n",
    "print('-'*50, file=open(logfile, 'a+'))\n",
    "print('Adversarial Test Results\\nPer-category AP: ', file=open(logfile, 'a+'))\n",
    "print('-'*50, file=open(logfile, 'a+'))\n",
    "print(f'Mean AP:  I  |  V  |  T  |  IV  |  IT  |  IVT ', file=open(logfile, 'a+'))\n",
    "print(f':::::: : {mAP_i_adv[\"mAP\"]:.4f} | {mAP_v_adv[\"mAP\"]:.4f} | {mAP_t_adv[\"mAP\"]:.4f} | {mAP_iv_adv[\"mAP\"]:.4f} | {mAP_it_adv[\"mAP\"]:.4f} | {mAP_ivt_adv[\"mAP\"]:.4f} ', file=open(logfile, 'a+'))\n",
    "print('='*50, file=open(logfile, 'a+'))\n",
    "print('-'*50, file=open(logfile, 'a+'))\n",
    "print(f'PSNR: {np.mean(psnr_values_list):.4f}    | SSIM: {np.mean(ssim_values_list):.4f}     | LPIPS: {1 - np.mean(lpips_values_list):.4f}', file=open(logfile, 'a+'))\n",
    "print('-'*50, file=open(logfile, 'a+'))\n",
    "print(\"Test results saved @ \", logfile)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd711eb1-85ec-4a2c-ba02-d8fcd99071f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_list = [4,8,16,32]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e6e3846-3e11-4a60-b89d-2305dc4017d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment started ...\n",
      "   logging outputs to:  weights/LogsTooba/FGSM-Attack.log\n",
      "DataLoader Started:\n",
      "Done...!. Printing Stats.\n",
      "DataLoader Started:\n",
      "Done...!. Printing Stats.\n",
      "DataLoader Started:\n",
      "Done...!. Printing Stats.\n",
      "DataLoader Started:\n",
      "Done...!. Printing Stats.\n",
      "DataLoader Started:\n",
      "Done...!. Printing Stats.\n",
      "DataLoader Started:\n",
      "Done...!. Printing Stats.\n",
      "DataLoader Started:\n",
      "Done...!. Printing Stats.\n",
      "DataLoader Started:\n",
      "Done...!. Printing Stats.\n",
      "DataLoader Started:\n",
      "Done...!. Printing Stats.\n",
      "Test results saved @  weights/LogsTooba/FGSM-Attack.log\n",
      "Test results saved @  weights/LogsTooba/FGSM-Attack.log\n"
     ]
    }
   ],
   "source": [
    "################### Perform FGSM attack using the hyper params ##################\n",
    "for eps in eps_list:\n",
    "    # Set FGSM parameters\n",
    "    eps = eps/255\n",
    "    exp_number = 1\n",
    "    \n",
    "    # Logs Saving File\n",
    "    version_adv = 'FGSM-Attack'\n",
    "    logfile  = f'weights/LogsTooba/{version_adv}.log'\n",
    "    \n",
    "    #%% log config\n",
    "    header1 = \"** Experiment for FGSM Attack **\"\n",
    "    header2 = \"** Eps: {}/255 **\".format(int(eps * 255) )\n",
    "    maxlen  = len(header1)\n",
    "\n",
    "    print(\"\\n\\n\\n{}\\n{}\\n{}\\n{}\\n\\n\".format(\"*\"*maxlen, header1, header2, \"*\"*maxlen), file=open(logfile, 'a+'))\n",
    "    print(\"Experiment started ...\\n   logging outputs to: \", logfile)\n",
    "    \n",
    "    mAP.reset_global()\n",
    "    mAP_adv.reset_global()\n",
    "    \n",
    "    mAPi.reset_global()\n",
    "    mAPv.reset_global()\n",
    "    mAPt.reset_global()\n",
    "    \n",
    "    mAPi_adv.reset_global()\n",
    "    mAPv_adv.reset_global()\n",
    "    mAPt_adv.reset_global()\n",
    "\n",
    "    psnr_values_list = []\n",
    "    ssim_values_list = []\n",
    "    lpips_values_list = []\n",
    "    lpips = piq.LPIPS()\n",
    "    \n",
    "    for test_dataloader in test_dataloaders:\n",
    "        # index = 1\n",
    "        test_adv(test_dataloader, model, activation, final_eval=True)\n",
    "        \n",
    "        # break\n",
    "        ###### Normal ######\n",
    "        print(\"Done...!. Printing Stats.\")\n",
    "    if set_chlg_eval:\n",
    "        mAP_i = mAP.compute_video_AP('i', ignore_null=set_chlg_eval)\n",
    "        mAP_v = mAP.compute_video_AP('v', ignore_null=set_chlg_eval)\n",
    "        mAP_t = mAP.compute_video_AP('t', ignore_null=set_chlg_eval)\n",
    "    else:\n",
    "        mAP_i = mAPi.compute_video_AP(ignore_null=set_chlg_eval)\n",
    "        mAP_v = mAPv.compute_video_AP(ignore_null=set_chlg_eval)\n",
    "        mAP_t = mAPt.compute_video_AP(ignore_null=set_chlg_eval)\n",
    "    \n",
    "    mAP_iv = mAP.compute_video_AP('iv', ignore_null=set_chlg_eval)\n",
    "    mAP_it = mAP.compute_video_AP('it', ignore_null=set_chlg_eval)\n",
    "    mAP_ivt = mAP.compute_video_AP('ivt', ignore_null=set_chlg_eval) \n",
    "    \n",
    "    ####### Adversarial Metrics #####\n",
    "    \n",
    "    if set_chlg_eval:\n",
    "        mAP_i_adv = mAP_adv.compute_video_AP('i', ignore_null=set_chlg_eval)\n",
    "        mAP_v_adv = mAP_adv.compute_video_AP('v', ignore_null=set_chlg_eval)\n",
    "        mAP_t_adv = mAP_adv.compute_video_AP('t', ignore_null=set_chlg_eval)\n",
    "    else:\n",
    "        mAP_i_adv = mAPi_adv.compute_video_AP(ignore_null=set_chlg_eval)\n",
    "        mAP_v_adv = mAPv_adv.compute_video_AP(ignore_null=set_chlg_eval)\n",
    "        mAP_t_adv = mAPt_adv.compute_video_AP(ignore_null=set_chlg_eval)\n",
    "    \n",
    "    mAP_iv_adv = mAP_adv.compute_video_AP('iv', ignore_null=set_chlg_eval)\n",
    "    mAP_it_adv = mAP_adv.compute_video_AP('it', ignore_null=set_chlg_eval)\n",
    "    mAP_ivt_adv = mAP_adv.compute_video_AP('ivt', ignore_null=set_chlg_eval) \n",
    "    \n",
    "    print('-'*50, file=open(logfile, 'a+'))\n",
    "    print('Test Results: ', file=open(logfile, 'a+'))\n",
    "    print('-'*50, file=open(logfile, 'a+'))\n",
    "    print(f'Mean AP:  I  |  V  |  T  |  IV  |  IT  |  IVT ', file=open(logfile, 'a+'))\n",
    "    print(f':::::: : {mAP_i[\"mAP\"]:.4f} | {mAP_v[\"mAP\"]:.4f} | {mAP_t[\"mAP\"]:.4f} | {mAP_iv[\"mAP\"]:.4f} | {mAP_it[\"mAP\"]:.4f} | {mAP_ivt[\"mAP\"]:.4f} ', file=open(logfile, 'a+'))\n",
    "    print('='*50, file=open(logfile, 'a+'))\n",
    "    print(\"Test results saved @ \", logfile)\n",
    "    \n",
    "    \n",
    "    print('-'*50, file=open(logfile, 'a+'))\n",
    "    print('Adversarial Test Results: ', file=open(logfile, 'a+'))\n",
    "    print('-'*50, file=open(logfile, 'a+'))\n",
    "    print(f'Mean AP:  I  |  V  |  T  |  IV  |  IT  |  IVT ', file=open(logfile, 'a+'))\n",
    "    print(f':::::: : {mAP_i_adv[\"mAP\"]:.4f} | {mAP_v_adv[\"mAP\"]:.4f} | {mAP_t_adv[\"mAP\"]:.4f} | {mAP_iv_adv[\"mAP\"]:.4f} | {mAP_it_adv[\"mAP\"]:.4f} | {mAP_ivt_adv[\"mAP\"]:.4f} ', file=open(logfile, 'a+'))\n",
    "    print('='*50, file=open(logfile, 'a+'))\n",
    "    print('-'*50, file=open(logfile, 'a+'))\n",
    "    print(f'PSNR: {np.mean(psnr_values_list):.4f}    | SSIM: {np.mean(ssim_values_list):.4f}     | LPIPS: {1 - np.mean(lpips_values_list):.4f}', file=open(logfile, 'a+'))\n",
    "    print('-'*50, file=open(logfile, 'a+'))\n",
    "    print(\"Test results saved @ \", logfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a957de9-bbd5-48e1-82fd-81a1d9792a64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c156aac-af94-4eed-97a4-fe019dfc52e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
