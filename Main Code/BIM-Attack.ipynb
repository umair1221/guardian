{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2736788-5995-4e9d-9ccc-39a63a0c7406",
   "metadata": {},
   "source": [
    "# Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "392a2f0b-7eb8-4c68-9300-d582bd194b49",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import torch\n",
    "import random\n",
    "import network\n",
    "import argparse\n",
    "import platform\n",
    "import ivtmetrics # You must \"pip install ivtmetrics\" to use\n",
    "import dataloader\n",
    "import numpy as np\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "import numpy as np\n",
    "# import lpips\n",
    "import piq\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "87d0903c-107a-41d8-ad36-21e8e6434a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% @args parsing\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument('--model', type=str, default='rendezvous', choices=['rendezvous'], help='Model name?')\n",
    "parser.add_argument('--version', type=int, default=0,  help='Model version control (for keeping several versions)') \n",
    "parser.add_argument('--hr_output', action='store_true', help='Whether to use higher resolution output (32x56) or not (8x14). Default: False')\n",
    "parser.add_argument('--use_ln', action='store_true', help='Whether to use layer norm or batch norm in AddNorm() function. Default: False')\n",
    "parser.add_argument('--decoder_layer', type=int, default=8, help='Number of MHMA layers ') \n",
    "# job\n",
    "parser.add_argument('-t', '--train', action='store_true', help='to train.')\n",
    "parser.add_argument('-e', '--test',  action='store_true', help='to test')\n",
    "parser.add_argument('--val_interval', type=int, default=1,  help='(for hp tuning). Epoch interval to evaluate on validation data. set -1 for only after final epoch, or a number higher than the total epochs to not validate.')\n",
    "# data\n",
    "parser.add_argument('--data_dir', type=str, default='/path/to/dataset', help='path to dataset?')\n",
    "parser.add_argument('--dataset_variant', type=str, default='cholect45-crossval', choices=['cholect50', 'cholect45', 'cholect50-challenge', 'cholect50-crossval', 'cholect45-crossval'], help='Variant of the dataset to use')\n",
    "parser.add_argument('-k', '--kfold', type=int, default=1,  choices=[1,2,3,4,5,], help='The test split in k-fold cross-validation')\n",
    "parser.add_argument('--image_width', type=int, default=448, help='Image width ')  \n",
    "parser.add_argument('--image_height', type=int, default=256, help='Image height ')  \n",
    "parser.add_argument('--image_channel', type=int, default=3, help='Image channels ')  \n",
    "parser.add_argument('--num_tool_classes', type=int, default=6, help='Number of tool categories')\n",
    "parser.add_argument('--num_verb_classes', type=int, default=10, help='Number of verb categories')\n",
    "parser.add_argument('--num_target_classes', type=int, default=15, help='Number of target categories')\n",
    "parser.add_argument('--num_triplet_classes', type=int, default=100, help='Number of triplet categories')\n",
    "parser.add_argument('--augmentation_list', type=str, nargs='*', default=['original', 'vflip', 'hflip', 'contrast', 'rot90'], help='List augumentation styles (see dataloader.py for list of supported styles).')\n",
    "# hp\n",
    "parser.add_argument('-b', '--batch', type=int, default=32,  help='The size of sample training batch')\n",
    "parser.add_argument('--epochs', type=int, default=100,  help='How many training epochs?')\n",
    "parser.add_argument('-w', '--warmups', type=int, nargs='+', default=[9,18,58], help='List warmup epochs for tool, verb-target, triplet respectively')\n",
    "parser.add_argument('-l', '--initial_learning_rates', type=float, nargs='+', default=[0.01, 0.01, 0.01], help='List learning rates for tool, verb-target, triplet respectively')\n",
    "parser.add_argument('--weight_decay', type=float, default=1e-5,  help='L2 regularization weight decay constant')\n",
    "parser.add_argument('--decay_steps', type=int, default=10,  help='Step to exponentially decay')\n",
    "parser.add_argument('--decay_rate', type=float, default=0.99,  help='Learning rates weight decay rate')\n",
    "parser.add_argument('--momentum', type=float, default=0.95,  help=\"Optimizer's momentum\")\n",
    "parser.add_argument('--power', type=float, default=0.1,  help='Learning rates weight decay power')\n",
    "# weights\n",
    "parser.add_argument('--pretrain_dir', type=str, default='', help='path to pretrain_weight?')\n",
    "parser.add_argument('--test_ckpt', type=str, default=None, help='path to model weight for testing')\n",
    "# device\n",
    "parser.add_argument('--gpu', type=str, default=\"0\",  help='The gpu device to use. To use multiple gpu put all the device ids comma-separated, e.g: \"0,1,2\" ')\n",
    "FLAGS, unparsed = parser.parse_known_args()\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01d0631d-f664-4141-b5a2-a2c982d92eff",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a6c2e5a-de5a-4caf-af2b-5b033622fe0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuring network ...\n"
     ]
    }
   ],
   "source": [
    "#%% @params definitions\n",
    "is_train        = FLAGS.train\n",
    "is_test         = FLAGS.test\n",
    "dataset_variant = FLAGS.dataset_variant\n",
    "data_dir        = FLAGS.data_dir\n",
    "kfold           = FLAGS.kfold if \"crossval\" in dataset_variant else 0\n",
    "version         = FLAGS.version\n",
    "hr_output       = FLAGS.hr_output\n",
    "use_ln          = FLAGS.use_ln\n",
    "batch_size      = FLAGS.batch\n",
    "pretrain_dir    = FLAGS.pretrain_dir\n",
    "test_ckpt       = FLAGS.test_ckpt\n",
    "weight_decay    = FLAGS.weight_decay\n",
    "learning_rates  = FLAGS.initial_learning_rates\n",
    "warmups         = FLAGS.warmups\n",
    "decay_steps     = FLAGS.decay_steps\n",
    "decay_rate      = FLAGS.decay_rate\n",
    "power           = FLAGS.power\n",
    "momentum        = FLAGS.momentum\n",
    "epochs          = FLAGS.epochs\n",
    "gpu             = FLAGS.gpu\n",
    "image_height    = FLAGS.image_height\n",
    "image_width     = FLAGS.image_width\n",
    "image_channel   = FLAGS.image_channel\n",
    "num_triplet     = FLAGS.num_triplet_classes\n",
    "num_tool        = FLAGS.num_tool_classes\n",
    "num_verb        = FLAGS.num_verb_classes\n",
    "num_target      = FLAGS.num_target_classes\n",
    "val_interval    = FLAGS.epochs-1 if FLAGS.val_interval==-1 else FLAGS.val_interval\n",
    "set_chlg_eval   = True if \"challenge\" in dataset_variant else False # To observe challenge evaluation protocol\n",
    "gpu             = \",\".join(str(FLAGS.gpu).split(\",\"))\n",
    "decodelayer     = FLAGS.decoder_layer\n",
    "addnorm         = \"layer\" if use_ln else \"batch\"\n",
    "modelsize       = \"high\" if hr_output else \"low\"\n",
    "FLAGS.multigpu  = len(gpu) > 1  # not yet implemented !\n",
    "mheaders        = [\"\",\"l\", \"cholect\", \"k\"]\n",
    "margs           = [FLAGS.model, decodelayer, dataset_variant, kfold]\n",
    "wheaders        = [\"norm\", \"res\"]\n",
    "wargs           = [addnorm, modelsize]\n",
    "modelname       = \"_\".join([\"{}{}\".format(x,y) for x,y in zip(mheaders, margs) if len(str(y))])+\"_\"+\\\n",
    "                  \"_\".join([\"{}{}\".format(x,y) for x,y in zip(wargs, wheaders) if len(str(x))])\n",
    "model_dir       = \"./__checkpoint__/run_{}\".format(version)\n",
    "\n",
    "if not os.path.exists(model_dir): os.makedirs(model_dir)\n",
    "resume_ckpt     = None\n",
    "ckpt_path       = os.path.join(model_dir, '{}.pth'.format(modelname))\n",
    "logfile         = os.path.join(model_dir, '{}.log'.format(modelname))\n",
    "data_augmentations      = FLAGS.augmentation_list \n",
    "iterable_augmentations  = []\n",
    "print(\"Configuring network ...\")\n",
    "\n",
    "#%% @functions (helpers)\n",
    "def assign_gpu(gpu=None):  \n",
    "    os.environ['CUDA_VISIBLE_DEVICES'] = str(gpu) \n",
    "    os.environ['TF_ENABLE_WINOGRAD_NONFUSED'] = '1' \n",
    "    \n",
    "\n",
    "def get_weight_balancing(case='cholect50'):\n",
    "    # 50:   cholecT50, data splits as used in rendezvous paper\n",
    "    # 50ch: cholecT50, data splits as used in CholecTriplet challenge\n",
    "    # 45cv: cholecT45, official data splits (cross-val)\n",
    "    # 50cv: cholecT50, official data splits (cross-val)\n",
    "    switcher = {\n",
    "        'cholect50': {\n",
    "            'tool'  :   [0.08084519, 0.81435289, 0.10459284, 2.55976864, 1.630372490, 1.29528455],\n",
    "            'verb'  :   [0.31956735, 0.07252306, 0.08111481, 0.81137309, 1.302895320, 2.12264151, 1.54109589, 8.86363636, 12.13692946, 0.40462028],\n",
    "            'target':   [0.06246232, 1.00000000, 0.34266478, 0.84750219, 14.80102041, 8.73795181, 1.52845100, 5.74455446, 0.285756500, 12.72368421, 0.6250808,  3.85771277, 6.95683453, 0.84923888, 0.40130032]\n",
    "        },\n",
    "        'cholect50-challenge': {\n",
    "            'tool':     [0.08495163, 0.88782288, 0.11259564, 2.61948830, 1.784866470, 1.144624170],\n",
    "            'verb':     [0.39862805, 0.06981640, 0.08332925, 0.81876204, 1.415868390, 2.269359150, 1.28428410, 7.35822511, 18.67857143, 0.45704490],\n",
    "            'target':   [0.07333818, 0.87139287, 0.42853950, 1.00000000, 17.67281106, 13.94545455, 1.44880997, 6.04889590, 0.326188650, 16.82017544, 0.63577586, 6.79964539, 6.19547658, 0.96284208, 0.51559559]\n",
    "        },\n",
    "        'cholect45-crossval': {\n",
    "            1: {\n",
    "                'tool':     [0.08165644, 0.91226868, 0.10674758, 2.85418156, 1.60554885, 1.10640067],\n",
    "                'verb':     [0.37870137, 0.06836869, 0.07931255, 0.84780024, 1.21880342, 2.52836879, 1.30765704, 6.88888889, 17.07784431, 0.45241117],\n",
    "                'target':   [0.07149629, 1.0, 0.41013597, 0.90458015, 13.06299213, 12.06545455, 1.5213205, 5.04255319, 0.35808332, 45.45205479, 0.67493897, 7.04458599, 9.14049587, 0.97330595, 0.52633249]\n",
    "                },\n",
    "            2: {\n",
    "                'tool':     [0.0854156, 0.89535362, 0.10995253, 2.74936869, 1.78264429, 1.13234529],\n",
    "                'verb':     [0.36346863, 0.06771776, 0.07893261, 0.82842725, 1.33892161, 2.13049748, 1.26120359, 5.72674419, 19.7, 0.43189126],\n",
    "                'target':   [0.07530655, 0.97961957, 0.4325135, 0.99393438, 15.5387931, 14.5951417, 1.53862569, 6.01836394, 0.35184462, 15.81140351, 0.709506, 5.79581994, 8.08295964, 1.0, 0.52689272]\n",
    "            },\n",
    "            3: {\n",
    "                \"tool\" :   [0.0915228, 0.89714969, 0.12057004, 2.72128174, 1.94092281, 1.12948557],\n",
    "                \"verb\" :   [0.43636862, 0.07558554, 0.0891017, 0.81820519, 1.53645582, 2.31924198, 1.28565657, 6.49387755, 18.28735632, 0.48676763],\n",
    "                \"target\" : [0.06841828, 0.90980736, 0.38826607, 1.0, 14.3640553, 12.9875, 1.25939394, 5.38341969, 0.29060227, 13.67105263, 0.59168565, 6.58985201, 5.72977941, 0.86824513, 0.47682423]\n",
    "\n",
    "            },\n",
    "            4: {\n",
    "                'tool':     [0.08222218, 0.85414117, 0.10948695, 2.50868784, 1.63235867, 1.20593318],\n",
    "                'verb':     [0.41154261, 0.0692142, 0.08427214, 0.79895288, 1.33625219, 2.2624166, 1.35343681, 7.63, 17.84795322, 0.43970609],\n",
    "                'target':   [0.07536126, 0.85398445, 0.4085784, 0.95464422, 15.90497738, 18.5978836, 1.55875831, 5.52672956, 0.33700863, 15.41666667, 0.74755423, 5.4921875, 6.11304348, 1.0, 0.50641118],\n",
    "            },\n",
    "            5: {\n",
    "                'tool':     [0.0804654, 0.92271157, 0.10489631, 2.52302243, 1.60074906, 1.09141982],\n",
    "                'verb':     [0.50710436, 0.06590258, 0.07981184, 0.81538866, 1.29267277, 2.20525568, 1.29699248, 7.32311321, 25.45081967, 0.46733895],\n",
    "                'target':   [0.07119395, 0.87450495, 0.43043372, 0.86465981, 14.01984127, 23.7114094, 1.47577277, 5.81085526, 0.32129865, 22.79354839, 0.63304067, 6.92745098, 5.88833333, 1.0, 0.53175798]\n",
    "            }\n",
    "        },\n",
    "        'cholect50-crossval': {\n",
    "            1:{\n",
    "                'tool':     [0.0828851, 0.8876, 0.10830995, 2.93907285, 1.63884786, 1.14499484],\n",
    "                'verb':     [0.29628942, 0.07366916, 0.08267971, 0.83155428, 1.25402434, 2.38358209, 1.34938741, 7.56872038, 12.98373984, 0.41502079],\n",
    "                'target':   [0.06551745, 1.0, 0.36345711, 0.82434783, 13.06299213, 8.61818182, 1.4017744, 4.62116992, 0.32822238, 45.45205479, 0.67343211, 4.13200498, 8.23325062, 0.88527215, 0.43113306],\n",
    "\n",
    "            },\n",
    "            2:{\n",
    "                'tool':     [0.08586283, 0.87716737, 0.11068887, 2.84210526, 1.81016949, 1.16283571],\n",
    "                'verb':     [0.30072757, 0.07275414, 0.08350168, 0.80694143, 1.39209979, 2.22754491, 1.31448763, 6.38931298, 13.89211618, 0.39397505],\n",
    "                'target':   [0.07056703, 1.0, 0.39451115, 0.91977006, 15.86206897, 9.68421053, 1.44483706, 5.44378698, 0.31858714, 16.14035088, 0.7238395, 4.20571429, 7.98264642, 0.91360477, 0.43304307],\n",
    "            },\n",
    "            3:{\n",
    "            'tool':      [0.09225068, 0.87856006, 0.12195811, 2.82669323, 1.97710987, 1.1603972],\n",
    "                'verb':     [0.34285159, 0.08049804, 0.0928239, 0.80685714, 1.56125608, 2.23984772, 1.31471136, 7.08835341, 12.17241379, 0.43180428],\n",
    "                'target':   [0.06919395, 1.0, 0.37532866, 0.9830703, 15.78801843, 8.99212598, 1.27597765, 5.36990596, 0.29177312, 15.02631579, 0.64935557, 5.08308605, 5.86643836, 0.86580743, 0.41908257], \n",
    "            },\n",
    "            4:{\n",
    "                'tool':     [0.08247885, 0.83095539, 0.11050268, 2.58193042, 1.64497676, 1.25538881],\n",
    "                'verb':     [0.31890981, 0.07380354, 0.08804592, 0.79094077, 1.35928144, 2.17017208, 1.42947103, 8.34558824, 13.19767442, 0.40666428],\n",
    "                'target':   [0.07777646, 0.95894072, 0.41993829, 0.95592153, 17.85972851, 12.49050633, 1.65701092, 5.74526929, 0.33763901, 17.31140351, 0.83747083, 3.95490982, 6.57833333, 1.0, 0.47139615],\n",
    "            },\n",
    "            5:{\n",
    "                'tool':     [0.07891691, 0.89878025, 0.10267677, 2.53805556, 1.60636428, 1.12691169],\n",
    "                'verb':     [0.36420961, 0.06825313, 0.08060635, 0.80956984, 1.30757221, 2.09375, 1.33625848, 7.9009434, 14.1350211, 0.41429631],\n",
    "                'target':   [0.07300329, 0.97128713, 0.42084942, 0.8829883, 15.57142857, 19.42574257, 1.56521739, 5.86547085, 0.32732733, 25.31612903, 0.70171674, 4.55220418, 6.13125, 1.0, 0.48528321],\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    return switcher.get(case)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b346c61f-cdd8-46df-a26b-53b730a700e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/umairnawaz/.conda/envs/myenv/lib/python3.9/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/home/umairnawaz/.conda/envs/myenv/lib/python3.9/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model built ...\n"
     ]
    }
   ],
   "source": [
    "test_ckpt = 'weights/rendezvous_l8_cholectcholect45-crossval_k1_batchnorm_lowres_180.pth'\n",
    "\n",
    "model = network.Rendezvous('resnet18', hr_output=hr_output, use_ln=use_ln).cuda()\n",
    "pytorch_total_params = sum(p.numel() for p in model.parameters())\n",
    "pytorch_train_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "\n",
    "#%% performance tracker for hp tuning\n",
    "benchmark   = torch.nn.Parameter(torch.tensor([0.0]), requires_grad=False)\n",
    "print(\"Model built ...\")\n",
    "\n",
    "# ckpt_path = os.path.join(model_dir, '{}.pth'.format(modelname))\n",
    "\n",
    "if os.path.exists(test_ckpt):\n",
    "    model.load_state_dict(torch.load(test_ckpt) ,  strict=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "88bbba74-e289-4e69-90bb-d8fea3e5539d",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.float = float    \n",
    "np.int = int   #module 'numpy' has no attribute 'int'\n",
    "np.object = object    #module 'numpy' has no attribute 'object'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6f56a35e-c1cf-4d83-98e2-7c734c433445",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metrics built ...\n"
     ]
    }
   ],
   "source": [
    "# Or constant weights from average of the random sampling of the dataset: we found this to produce better result.\n",
    "tool_weight     = [0.93487068, 0.94234964, 0.93487068, 1.18448115, 1.02368339, 0.97974447]\n",
    "verb_weight     = [0.60002400, 0.60002400, 0.60002400, 0.61682467, 0.67082683, 0.80163207, 0.70562823, 2.11208448, 2.69230769, 0.60062402]\n",
    "target_weight   = [0.49752894, 0.52041527, 0.49752894, 0.51394739, 2.71899565, 1.75577963, 0.58509403, 1.25228034, 0.49752894, 2.42993134, 0.49802647, 0.87266576, 1.36074165, 0.50150917, 0.49802647]\n",
    "\n",
    "\n",
    "#%% Loss\n",
    "activation  = nn.Sigmoid()\n",
    "loss_fn_i   = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(tool_weight).cuda())\n",
    "loss_fn_v   = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(verb_weight).cuda())\n",
    "loss_fn_t   = nn.BCEWithLogitsLoss(pos_weight=torch.tensor(target_weight).cuda())\n",
    "loss_fn_ivt = nn.BCEWithLogitsLoss()\n",
    "\n",
    "\n",
    "#%% evaluation metrics\n",
    "mAP = ivtmetrics.Recognition(100)\n",
    "mAP.reset_global()\n",
    "if not set_chlg_eval:\n",
    "    mAPi = ivtmetrics.Recognition(6)\n",
    "    mAPv = ivtmetrics.Recognition(10)\n",
    "    mAPt = ivtmetrics.Recognition(15)\n",
    "    mAPi.reset_global()\n",
    "    mAPv.reset_global()\n",
    "    mAPt.reset_global()\n",
    "\n",
    "#%% Adversarial metrics\n",
    "mAP_adv = ivtmetrics.Recognition(100)\n",
    "mAP_adv.reset_global()\n",
    "if not set_chlg_eval:\n",
    "    mAPi_adv = ivtmetrics.Recognition(6)\n",
    "    mAPv_adv = ivtmetrics.Recognition(10)\n",
    "    mAPt_adv = ivtmetrics.Recognition(15)\n",
    "    mAPi_adv.reset_global()\n",
    "    mAPv_adv.reset_global()\n",
    "    mAPt_adv.reset_global()\n",
    "print(\"Metrics built ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226286e7-1862-4519-8dfb-ae4ee8cc0ed2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "aeacc7d1-7acf-41df-929b-8d7d50bc4ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#%% data loading : variant and split selection (Note: original paper used different augumentation per epoch)\n",
    "data_dir = '/share/sdb/umairnawaz/Data/'\n",
    "dataset_variant= 'cholect45-crossval'\n",
    "dataset = dataloader.CholecT50( \n",
    "            dataset_dir=data_dir, \n",
    "            dataset_variant=dataset_variant,\n",
    "            test_fold=kfold,\n",
    "            augmentation_list=data_augmentations,\n",
    "            )\n",
    "\n",
    "# build dataset\n",
    "train_dataset, val_dataset, test_dataset = dataset.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "305a37cd-b2be-479d-8ebf-e75a5a2a4b23",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c9bb56a-d89c-479d-a29e-b4877cfd973f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset loaded ...\n"
     ]
    }
   ],
   "source": [
    "test_dataloaders = []\n",
    "for video_dataset in test_dataset:\n",
    "    test_dataloader = DataLoader(video_dataset, batch_size=batch_size, shuffle=False, prefetch_factor=3*batch_size, num_workers=3, pin_memory=True, persistent_workers=True, drop_last=False)\n",
    "    test_dataloaders.append(test_dataloader)\n",
    "print(\"Dataset loaded ...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "167d4d78-9369-48b0-96e7-98857de04f00",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/share/sdb/umairnawaz/Data/data/VID02'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_dataloaders[1].dataset.img_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7cd8b046-6361-4824-ba7e-5832060090c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataset.ConcatDataset at 0x7fe5e79b3790>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8cbdd757-32b7-42ac-8138-d72f285f922a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.transforms as transforms\n",
    "# from torch.autograd.gradcheck import zero_gradients\n",
    "from PIL import Image\n",
    "\n",
    "def zero_gradients(x):\n",
    "    if isinstance(x, torch.Tensor):\n",
    "        if x.grad is not None:\n",
    "            x.grad.detach_()\n",
    "            x.grad.zero_()\n",
    "    elif isinstance(x, collections.abc.Iterable):\n",
    "        for elem in x:\n",
    "            zero_gradients(elem)\n",
    "\n",
    "# Function to perform PGD attack\n",
    "def basic_iterative_method(norm_model, x, y, num_steps=10, alpha=2/255, eps=8/255):\n",
    "    # Adversarial Attack Images\n",
    "    # x_adv = x.clone().detach().requires_grad_(True)\n",
    "    # x_adv = normalize_to_01(x_adv)\n",
    "\n",
    "    # Original Images\n",
    "    x = x.clone().detach().cuda()\n",
    "    # x_norm = normalize_to_01(x_norm)\n",
    "\n",
    "    # if random_start:\n",
    "    #     # Start with uniformly random point\n",
    "    #     x_adv = x_adv + torch.empty_like(x_adv).uniform_(-eps , eps)\n",
    "    #     x_adv = torch.clamp(x_adv, min=0, max=1).detach()\n",
    "    # x_adv = torch.rand_like(x, requires_grad=True).cuda()\n",
    "\n",
    "    ori_images = x.clone().detach().cuda()\n",
    "    \n",
    "    norm = True\n",
    "    targeted = False  # Change to True if we have a targeted attack\n",
    "    y_target = None    # Set the target label if it's a targeted attack\n",
    "    \n",
    "    for _ in range(num_steps):\n",
    "        x = x.clone().detach().requires_grad_(True)  # Create a new leaf variable\n",
    "        # x_adv.requires_grad = True\n",
    "        # zero_gradients(x_adv)  # Zero the gradients\n",
    "\n",
    "        # if norm:\n",
    "            # Assuming 'normalized_image' is your normalized image tensor\n",
    "            # min_x = x.min()  # Replace with the actual minimum value of the original image\n",
    "            # max_x = x.max()   # Replace with the actual maximum value of the original image\n",
    "            \n",
    "            # Denormalize the image tensor to the original range\n",
    "            # x_model = denormalize_from_01(x, ranges[0].float(), ranges[1].float())\n",
    "            # print(\"Original Range: \" , x_model.min(), x_model.max())\n",
    "            # print(\"Fake Range: \" , x.min(), x.max())\n",
    "\n",
    "\n",
    "        # resnet_model = nn.Sequential(\n",
    "        #     normalize,\n",
    "        #     model\n",
    "        # ).to(device)\n",
    "        # resnet_model = resnet_model.eval()\n",
    "        # Forward pass\n",
    "        tool, verb, target, triplet = norm_model(x)\n",
    "\n",
    "        # Normalize back to 0 and 1\n",
    "        # x_norm = normalize_to_01(x_norm)\n",
    "        # print(\"Adversarial Range: \" , x_adv.min(), x_adv.max())\n",
    "        # if final_eval and not set_chlg_eval:\n",
    "        \n",
    "        cam_i, logit_i  = tool\n",
    "        cam_v, logit_v  = verb\n",
    "        cam_t, logit_t  = target\n",
    "        logit_ivt       = triplet            \n",
    "\n",
    "        # Compute Loss\n",
    "        loss_i          = loss_fn_i(logit_i, y[0].float())\n",
    "        loss_v          = loss_fn_v(logit_v, y[1].float())\n",
    "        loss_t          = loss_fn_t(logit_t, y[2].float())\n",
    "        loss_ivt        = loss_fn_ivt(logit_ivt, y[3].float())  \n",
    "\n",
    "        # Total Loss\n",
    "        loss            = (loss_i) + (loss_v) + (loss_t) + loss_ivt \n",
    "\n",
    "        # Backward pass\n",
    "        # loss.backward()\n",
    "        # print(\"Backward Done: \")\n",
    "\n",
    "        # Ensure x_adv has gradients\n",
    "        # if x_adv.grad is None:\n",
    "        #     x_adv.grad = torch.zeros_like(x_adv)\n",
    "        \n",
    "        # PGD step Implemented using Blog\n",
    "        # with torch.no_grad():\n",
    "        #     # print(\"Progress\")\n",
    "        #     x_adv.requires_grad_(True)\n",
    "        #     x_adv -= alpha * x_adv.grad.sign()\n",
    "        #     x_adv = torch.clamp(x_adv, x - eps, x + eps)\n",
    "        #     x_adv = torch.clamp(x_adv, 0, 1)  # Ensure pixel values are in [0, 1]\n",
    "\n",
    "        # PGD using TorchAttack Library\n",
    "        # Update adversarial images\n",
    "        grad = torch.autograd.grad(\n",
    "            loss, x, retain_graph=False, create_graph=False, allow_unused=True\n",
    "        )[0]\n",
    "        if grad is not None:\n",
    "            # print(\"Hi\")\n",
    "            adv_images = x + alpha * grad.sign()\n",
    "            a = torch.clamp(ori_images - eps, min=0)\n",
    "            b = (adv_images >= a).float() * adv_images + (\n",
    "                adv_images < a\n",
    "            ).float() * a  # nopep8\n",
    "            c = (b > ori_images + eps).float() * (ori_images + eps) + (\n",
    "                b <= ori_images + eps\n",
    "            ).float() * b  # nopep8\n",
    "            x = torch.clamp(c, max=1).detach()\n",
    "\n",
    "    # print(x.min() , x.max())\n",
    "    # print(\"Final Shape: \" , x_adv.shape)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "41ddb564-057b-4e5f-ba64-dee7c3a8db28",
   "metadata": {},
   "outputs": [],
   "source": [
    "normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "norm_model = nn.Sequential(\n",
    "            normalize,\n",
    "            model\n",
    "        ).to(device)\n",
    "norm_model = norm_model.eval()\n",
    "\n",
    "def test_adv(dataloader, model, activation, final_eval=False):\n",
    "    mAP.reset()  \n",
    "    if final_eval and not set_chlg_eval:\n",
    "        mAPv.reset() \n",
    "        mAPt.reset() \n",
    "        mAPi.reset()\n",
    "    \n",
    "    # Adversarial Metrics\n",
    "    mAP_adv.reset()  \n",
    "    if final_eval and not set_chlg_eval:\n",
    "        mAPv_adv.reset() \n",
    "        mAPt_adv.reset() \n",
    "        mAPi_adv.reset()\n",
    "\n",
    "    \n",
    "    print(\"DataLoader Started:\")\n",
    "    for batch, (img, (y1, y2, y3, y4)) in enumerate(dataloader):\n",
    "        img, y1, y2, y3, y4 = img.cuda(), y1.cuda(), y2.cuda(), y3.cuda(), y4.cuda()\n",
    "        # model.eval()\n",
    "\n",
    "        #################### Normal Testing #####################\n",
    "        # img = denormalize_from_01(img, img_min, img_max):\n",
    "        tool, verb, target, triplet = norm_model(img)\n",
    "        \n",
    "        if final_eval:\n",
    "            cam_i, logit_i = tool\n",
    "            cam_v, logit_v = verb\n",
    "            cam_t, logit_t = target\n",
    "            mAPi.update(y1.float().detach().cpu(), activation(logit_i).detach().cpu()) # Log metrics \n",
    "            mAPv.update(y2.float().detach().cpu(), activation(logit_v).detach().cpu()) # Log metrics \n",
    "            mAPt.update(y3.float().detach().cpu(), activation(logit_t).detach().cpu()) # Log metrics \n",
    "        mAP.update(y4.float().detach().cpu(), activation(triplet).detach().cpu()) # Log metrics \n",
    "\n",
    "\n",
    "        ############# Adversarial Attack Started ##############\n",
    "        # img_min , img_max = img.min() , img.max()\n",
    "        # img = normalize_to_01(img)\n",
    "        adversarial_example = basic_iterative_method(norm_model, img, (y1, y2, y3, y4),\n",
    "                                                 num_steps, alpha, eps )\n",
    "        # for i , img_adv in enumerate(adversarial_example):\n",
    "        #     save_image(img[i], f'Images-Attack/Clean/img{i}-{batch}.png')\n",
    "        #     save_image(img_adv, f'Images-Attack/Adv/img-adv{i}-{batch}.png')\n",
    "\n",
    "        #### Finding Metrics for Image Quality ####\n",
    "\n",
    "        # adversarial_example = normalize_to_01(adversarial_example)\n",
    "        # img = normalize_to_01(img)\n",
    "        psnr_values_list.append(piq.psnr(adversarial_example, img).item())\n",
    "        ssim_values_list.append(piq.ssim(adversarial_example, img).item())\n",
    "        lpips_values_list.append(lpips(2*adversarial_example-1, 2*img-1).item())\n",
    "        \n",
    "        # break\n",
    "        \n",
    "\n",
    "        ######################## Adversarial Testing ########################\n",
    "        \n",
    "        tool_adv, verb_adv, target_adv, triplet_adv = norm_model(adversarial_example)\n",
    "        \n",
    "        # _, predicted_adv_tool = torch.max(tool_adv[1].data, 1)  # Assuming tool_adv[1] contains the logits\n",
    "        # _, predicted_adv_verb = torch.max(verb_adv[1].data, 1)  # Assuming verb_adv[1] contains the logits\n",
    "        # _, predicted_adv_target = torch.max(target_adv[1].data, 1)  # Assuming target_adv[1] contains the logits\n",
    "        \n",
    "        if final_eval:\n",
    "            cam_i, logit_i_adv = tool_adv\n",
    "            cam_v, logit_v_adv = verb_adv\n",
    "            cam_t, logit_t_adv = target_adv\n",
    "            mAPi_adv.update(y1.float().detach().cpu(), activation(logit_i_adv).detach().cpu()) # Log metrics \n",
    "            mAPv_adv.update(y2.float().detach().cpu(), activation(logit_v_adv).detach().cpu()) # Log metrics \n",
    "            mAPt_adv.update(y3.float().detach().cpu(), activation(logit_t_adv).detach().cpu()) # Log metrics \n",
    "        mAP_adv.update(y4.float().detach().cpu(), activation(triplet_adv).detach().cpu()) # Log metrics \n",
    "\n",
    "    if final_eval:\n",
    "        mAPv.video_end()\n",
    "        mAPt.video_end()\n",
    "        mAPi.video_end()\n",
    "        \n",
    "    if final_eval:\n",
    "        mAPv_adv.video_end()\n",
    "        mAPt_adv.video_end()\n",
    "        mAPi_adv.video_end()\n",
    "\n",
    "        # print(f'Original Tool Prediction: {predicted_original_tool}')\n",
    "        # print(f'Adversarial Tool Prediction: {predicted_adv_tool}') \n",
    "        \n",
    "        # print(f'Original Verb Prediction: {predicted_original_verb}')\n",
    "        # print(f'Adversarial Verb Prediction: {predicted_adv_verb}')\n",
    "        \n",
    "        # print(f'Original Target Prediction: {predicted_original_target}')\n",
    "        # print(f'Adversarial Target Prediction: {predicted_adv_target}')\n",
    "\n",
    "        # print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5c6a684-0370-43d7-97de-2f1f1533d8f2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34804c74-adbc-42d5-a9b5-5e5598d2d917",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7a541c24-423d-42ec-81ac-32bc2cf33fd0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment started ...\n",
      "   logging outputs to:  weights/Logs/BIM-Attack-TorchAttack.log\n",
      "DataLoader Started:\n",
      "Done...!. Printing Stats.\n",
      "DataLoader Started:\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[19], line 42\u001b[0m\n\u001b[1;32m     38\u001b[0m lpips \u001b[38;5;241m=\u001b[39m piq\u001b[38;5;241m.\u001b[39mLPIPS()\n\u001b[1;32m     40\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m test_dataloader \u001b[38;5;129;01min\u001b[39;00m test_dataloaders:\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;66;03m# index = 1\u001b[39;00m\n\u001b[0;32m---> 42\u001b[0m     \u001b[43mtest_adv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtest_dataloader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mactivation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;66;03m# break\u001b[39;00m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;66;03m###### Normal ######\u001b[39;00m\n\u001b[1;32m     46\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDone...!. Printing Stats.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[0;32mIn[18], line 47\u001b[0m, in \u001b[0;36mtest_adv\u001b[0;34m(dataloader, model, activation, final_eval)\u001b[0m\n\u001b[1;32m     41\u001b[0m mAP\u001b[38;5;241m.\u001b[39mupdate(y4\u001b[38;5;241m.\u001b[39mfloat()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu(), activation(triplet)\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mcpu()) \u001b[38;5;66;03m# Log metrics \u001b[39;00m\n\u001b[1;32m     44\u001b[0m \u001b[38;5;66;03m############# Adversarial Attack Started ##############\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;66;03m# img_min , img_max = img.min() , img.max()\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# img = normalize_to_01(img)\u001b[39;00m\n\u001b[0;32m---> 47\u001b[0m adversarial_example \u001b[38;5;241m=\u001b[39m \u001b[43mbasic_iterative_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnorm_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43my1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my3\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my4\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     48\u001b[0m \u001b[43m                                         \u001b[49m\u001b[43mnum_steps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43malpha\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meps\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     49\u001b[0m \u001b[38;5;66;03m# for i , img_adv in enumerate(adversarial_example):\u001b[39;00m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m#     save_image(img[i], f'Images-Attack/Clean/img{i}-{batch}.png')\u001b[39;00m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m#     save_image(img_adv, f'Images-Attack/Adv/img-adv{i}-{batch}.png')\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# adversarial_example = normalize_to_01(adversarial_example)\u001b[39;00m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# img = normalize_to_01(img)\u001b[39;00m\n\u001b[1;32m     57\u001b[0m psnr_values_list\u001b[38;5;241m.\u001b[39mappend(piq\u001b[38;5;241m.\u001b[39mpsnr(adversarial_example, img)\u001b[38;5;241m.\u001b[39mitem())\n",
      "Cell \u001b[0;32mIn[14], line 99\u001b[0m, in \u001b[0;36mbasic_iterative_method\u001b[0;34m(norm_model, x, y, num_steps, alpha, eps)\u001b[0m\n\u001b[1;32m     79\u001b[0m loss            \u001b[38;5;241m=\u001b[39m (loss_i) \u001b[38;5;241m+\u001b[39m (loss_v) \u001b[38;5;241m+\u001b[39m (loss_t) \u001b[38;5;241m+\u001b[39m loss_ivt \n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# Backward pass\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;66;03m# loss.backward()\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[38;5;66;03m# print(\"Backward Done: \")\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[38;5;66;03m# PGD using TorchAttack Library\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[38;5;66;03m# Update adversarial images\u001b[39;00m\n\u001b[0;32m---> 99\u001b[0m grad \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgrad\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m    \u001b[49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mallow_unused\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[1;32m    101\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m grad \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    103\u001b[0m     \u001b[38;5;66;03m# print(\"Hi\")\u001b[39;00m\n\u001b[1;32m    104\u001b[0m     adv_images \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m alpha \u001b[38;5;241m*\u001b[39m grad\u001b[38;5;241m.\u001b[39msign()\n",
      "File \u001b[0;32m~/.conda/envs/myenv/lib/python3.9/site-packages/torch/autograd/__init__.py:303\u001b[0m, in \u001b[0;36mgrad\u001b[0;34m(outputs, inputs, grad_outputs, retain_graph, create_graph, only_inputs, allow_unused, is_grads_batched)\u001b[0m\n\u001b[1;32m    301\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _vmap_internals\u001b[38;5;241m.\u001b[39m_vmap(vjp, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m0\u001b[39m, allow_none_pass_through\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)(grad_outputs_)\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 303\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    304\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_outputs_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt_inputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    305\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_unused\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "################### Perform BIM attack ##################\n",
    "\n",
    "# Set BIM parameters\n",
    "num_steps = 10\n",
    "alpha = 4/255\n",
    "eps = 8/255\n",
    "\n",
    "# Logs Saving File\n",
    "version_adv = 'BIM-Attack-TorchAttack'\n",
    "logfile  = f'weights/Logs/{version_adv}.log'\n",
    "\n",
    "#%% log config\n",
    "header1 = \"** Experiment for BIM Attack **\"\n",
    "header2 = \"** Num_Steps: {} | Alpha: {}/255 | Eps: {}/255 **\".format(num_steps, int(alpha * 255), int(eps * 255))\n",
    "# header3 = \"** LR Config: Init: {} | Peak: {} | Warmup Epoch: {} | Rise: {} | Decay {} | train params {} | all params {} **\".format([float(f'{sch.get_last_lr()[0]:.6f}') for sch in lr_schedulers], [float(f'{v:.6f}') for v in wp_lr], warmups, power, decay_rate, pytorch_train_params, pytorch_total_params)\n",
    "maxlen  = len(header1)\n",
    "# header1 = \"{}{}{}\".format('*'*((maxlen-len(header1))//2+1), header1, '*'*((maxlen-len(header1))//2+1) )\n",
    "# header2 = \"{}{}{}\".format('*'*((maxlen-len(header2))//2+1), header2, '*'*((maxlen-len(header2))//2+1) )\n",
    "# header3 = \"{}{}{}\".format('*'*((maxlen-len(header3))//2+1), header3, '*'*((maxlen-len(header3))//2+1) )\n",
    "# maxlen  = max(len(header1), len(header2), len(header3))\n",
    "print(\"\\n\\n\\n{}\\n{}\\n{}\\n{}\\n\\n\".format(\"*\"*maxlen, header1, header2, \"*\"*maxlen), file=open(logfile, 'a+'))\n",
    "print(\"Experiment started ...\\n   logging outputs to: \", logfile)\n",
    "\n",
    "mAP.reset_global()\n",
    "mAP_adv.reset_global()\n",
    "\n",
    "mAPi.reset_global()\n",
    "mAPv.reset_global()\n",
    "mAPt.reset_global()\n",
    "\n",
    "mAPi_adv.reset_global()\n",
    "mAPv_adv.reset_global()\n",
    "mAPt_adv.reset_global()\n",
    "\n",
    "psnr_values_list = []\n",
    "ssim_values_list = []\n",
    "lpips_values_list = []\n",
    "lpips = piq.LPIPS()\n",
    "\n",
    "for test_dataloader in test_dataloaders:\n",
    "    # index = 1\n",
    "    test_adv(test_dataloader, model, activation, final_eval=True)\n",
    "    \n",
    "    # break\n",
    "    ###### Normal ######\n",
    "    print(\"Done...!. Printing Stats.\")\n",
    "\n",
    "if set_chlg_eval:\n",
    "    mAP_i = mAP.compute_video_AP('i', ignore_null=set_chlg_eval)\n",
    "    mAP_v = mAP.compute_video_AP('v', ignore_null=set_chlg_eval)\n",
    "    mAP_t = mAP.compute_video_AP('t', ignore_null=set_chlg_eval)\n",
    "else:\n",
    "    mAP_i = mAPi.compute_video_AP(ignore_null=set_chlg_eval)\n",
    "    mAP_v = mAPv.compute_video_AP(ignore_null=set_chlg_eval)\n",
    "    mAP_t = mAPt.compute_video_AP(ignore_null=set_chlg_eval)\n",
    "\n",
    "mAP_iv = mAP.compute_video_AP('iv', ignore_null=set_chlg_eval)\n",
    "mAP_it = mAP.compute_video_AP('it', ignore_null=set_chlg_eval)\n",
    "mAP_ivt = mAP.compute_video_AP('ivt', ignore_null=set_chlg_eval) \n",
    "\n",
    "####### Adversarial Metrics #####\n",
    "\n",
    "if set_chlg_eval:\n",
    "    mAP_i_adv = mAP_adv.compute_video_AP('i', ignore_null=set_chlg_eval)\n",
    "    mAP_v_adv = mAP_adv.compute_video_AP('v', ignore_null=set_chlg_eval)\n",
    "    mAP_t_adv = mAP_adv.compute_video_AP('t', ignore_null=set_chlg_eval)\n",
    "else:\n",
    "    mAP_i_adv = mAPi_adv.compute_video_AP(ignore_null=set_chlg_eval)\n",
    "    mAP_v_adv = mAPv_adv.compute_video_AP(ignore_null=set_chlg_eval)\n",
    "    mAP_t_adv = mAPt_adv.compute_video_AP(ignore_null=set_chlg_eval)\n",
    "\n",
    "mAP_iv_adv = mAP_adv.compute_video_AP('iv', ignore_null=set_chlg_eval)\n",
    "mAP_it_adv = mAP_adv.compute_video_AP('it', ignore_null=set_chlg_eval)\n",
    "mAP_ivt_adv = mAP_adv.compute_video_AP('ivt', ignore_null=set_chlg_eval) \n",
    "\n",
    "print('-'*50, file=open(logfile, 'a+'))\n",
    "print('Test Results\\nPer-category AP: ', file=open(logfile, 'a+'))\n",
    "# print(f'I   : {mAP_i[\"AP\"]}', file=open(logfile, 'a+'))\n",
    "# print(f'V   : {mAP_v[\"AP\"]}', file=open(logfile, 'a+'))\n",
    "# print(f'T   : {mAP_t[\"AP\"]}', file=open(logfile, 'a+'))\n",
    "# print(f'IV  : {mAP_iv[\"AP\"]}', file=open(logfile, 'a+'))\n",
    "# print(f'IT  : {mAP_it[\"AP\"]}', file=open(logfile, 'a+'))\n",
    "# print(f'IVT : {mAP_ivt[\"AP\"]}', file=open(logfile, 'a+'))\n",
    "print('-'*50, file=open(logfile, 'a+'))\n",
    "print(f'Mean AP:  I  |  V  |  T  |  IV  |  IT  |  IVT ', file=open(logfile, 'a+'))\n",
    "print(f':::::: : {mAP_i[\"mAP\"]:.4f} | {mAP_v[\"mAP\"]:.4f} | {mAP_t[\"mAP\"]:.4f} | {mAP_iv[\"mAP\"]:.4f} | {mAP_it[\"mAP\"]:.4f} | {mAP_ivt[\"mAP\"]:.4f} ', file=open(logfile, 'a+'))\n",
    "print('='*50, file=open(logfile, 'a+'))\n",
    "print(\"Test results saved @ \", logfile)\n",
    "\n",
    "\n",
    "print('-'*50, file=open(logfile, 'a+'))\n",
    "print('Adversarial Test Results: ', file=open(logfile, 'a+'))\n",
    "\n",
    "print('-'*50, file=open(logfile, 'a+'))\n",
    "print(f'Mean AP:  I  |  V  |  T  |  IV  |  IT  |  IVT ', file=open(logfile, 'a+'))\n",
    "print(f':::::: : {mAP_i_adv[\"mAP\"]:.4f} | {mAP_v_adv[\"mAP\"]:.4f} | {mAP_t_adv[\"mAP\"]:.4f} | {mAP_iv_adv[\"mAP\"]:.4f} | {mAP_it_adv[\"mAP\"]:.4f} | {mAP_ivt_adv[\"mAP\"]:.4f} ', file=open(logfile, 'a+'))\n",
    "print('='*50, file=open(logfile, 'a+'))\n",
    "print('-'*50, file=open(logfile, 'a+'))\n",
    "print(f'PSNR: {np.mean(psnr_values_list):.4f}    | SSIM: {np.mean(ssim_values_list):.4f}     | LPIPS: {1 - np.mean(lpips_values_list):.4f}', file=open(logfile, 'a+'))\n",
    "print('-'*50, file=open(logfile, 'a+'))\n",
    "print(\"Test results saved @ \", logfile)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9bade65-bfb4-4982-aac5-f2e07a58c525",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ca9fbcd5-1b42-4551-9ff9-ef320e093236",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exp No. 1\n",
    "# num_steps = 10\n",
    "# alpha = 4\n",
    "# eps_list = [4,8,16,32]\n",
    "\n",
    "# # Exp No. 2\n",
    "# num_steps = 10\n",
    "# alpha_list = [2,4,8,16]\n",
    "# eps = 8\n",
    "\n",
    "# # Exp No. 3\n",
    "num_steps_list = [5,10,15,20]\n",
    "alpha = 4\n",
    "eps = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c906ee5-54ea-41c7-ae78-cd73c4553103",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a33a21de-50bb-4dd8-b03e-65879cfd6e47",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment started ...\n",
      "   logging outputs to:  weights/Logs/BIM-Attack-TorchAttack.log\n",
      "DataLoader Started:\n",
      "Done...!. Printing Stats.\n",
      "DataLoader Started:\n",
      "Done...!. Printing Stats.\n",
      "DataLoader Started:\n",
      "Done...!. Printing Stats.\n",
      "DataLoader Started:\n",
      "Done...!. Printing Stats.\n",
      "DataLoader Started:\n",
      "Done...!. Printing Stats.\n",
      "DataLoader Started:\n",
      "Done...!. Printing Stats.\n",
      "DataLoader Started:\n",
      "Done...!. Printing Stats.\n",
      "DataLoader Started:\n",
      "Done...!. Printing Stats.\n",
      "DataLoader Started:\n",
      "Done...!. Printing Stats.\n",
      "Test results saved @  weights/Logs/BIM-Attack-TorchAttack.log\n",
      "Test results saved @  weights/Logs/BIM-Attack-TorchAttack.log\n",
      "Experiment started ...\n",
      "   logging outputs to:  weights/Logs/BIM-Attack-TorchAttack.log\n",
      "DataLoader Started:\n",
      "Done...!. Printing Stats.\n",
      "DataLoader Started:\n",
      "Done...!. Printing Stats.\n",
      "DataLoader Started:\n",
      "Done...!. Printing Stats.\n",
      "DataLoader Started:\n",
      "Done...!. Printing Stats.\n",
      "DataLoader Started:\n",
      "Done...!. Printing Stats.\n",
      "DataLoader Started:\n",
      "Done...!. Printing Stats.\n",
      "DataLoader Started:\n",
      "Done...!. Printing Stats.\n",
      "DataLoader Started:\n",
      "Done...!. Printing Stats.\n",
      "DataLoader Started:\n",
      "Done...!. Printing Stats.\n",
      "Test results saved @  weights/Logs/BIM-Attack-TorchAttack.log\n",
      "Test results saved @  weights/Logs/BIM-Attack-TorchAttack.log\n",
      "Experiment started ...\n",
      "   logging outputs to:  weights/Logs/BIM-Attack-TorchAttack.log\n",
      "DataLoader Started:\n",
      "Done...!. Printing Stats.\n",
      "DataLoader Started:\n",
      "Done...!. Printing Stats.\n",
      "DataLoader Started:\n",
      "Done...!. Printing Stats.\n",
      "DataLoader Started:\n",
      "Done...!. Printing Stats.\n",
      "DataLoader Started:\n",
      "Done...!. Printing Stats.\n",
      "DataLoader Started:\n",
      "Done...!. Printing Stats.\n",
      "DataLoader Started:\n",
      "Done...!. Printing Stats.\n",
      "DataLoader Started:\n",
      "Done...!. Printing Stats.\n",
      "DataLoader Started:\n",
      "Done...!. Printing Stats.\n",
      "Test results saved @  weights/Logs/BIM-Attack-TorchAttack.log\n",
      "Test results saved @  weights/Logs/BIM-Attack-TorchAttack.log\n",
      "Experiment started ...\n",
      "   logging outputs to:  weights/Logs/BIM-Attack-TorchAttack.log\n",
      "DataLoader Started:\n",
      "Done...!. Printing Stats.\n",
      "DataLoader Started:\n",
      "Done...!. Printing Stats.\n",
      "DataLoader Started:\n",
      "Done...!. Printing Stats.\n",
      "DataLoader Started:\n",
      "Done...!. Printing Stats.\n",
      "DataLoader Started:\n",
      "Done...!. Printing Stats.\n",
      "DataLoader Started:\n",
      "Done...!. Printing Stats.\n",
      "DataLoader Started:\n",
      "Done...!. Printing Stats.\n",
      "DataLoader Started:\n",
      "Done...!. Printing Stats.\n",
      "DataLoader Started:\n",
      "Done...!. Printing Stats.\n",
      "Test results saved @  weights/Logs/BIM-Attack-TorchAttack.log\n",
      "Test results saved @  weights/Logs/BIM-Attack-TorchAttack.log\n"
     ]
    }
   ],
   "source": [
    "eps = eps/255\n",
    "alpha = alpha/255\n",
    "for num_steps in num_steps_list:\n",
    "    ################### Perform BIM attack ##################\n",
    "\n",
    "    # Set PGD parameters\n",
    "    # num_steps = 10\n",
    "    # alpha = 4/255\n",
    "    # alpha = alpha/255\n",
    "    \n",
    "    # Logs Saving File\n",
    "    version_adv = 'BIM-Attack-TorchAttack'\n",
    "    logfile  = f'weights/Logs/{version_adv}.log'\n",
    "    \n",
    "    #%% log config\n",
    "    header1 = \"** Experiment for BIM Attack **\"\n",
    "    header2 = \"** Num_Steps: {} | Alpha: {}/255 | Eps: {}/255 **\".format(num_steps, int(alpha * 255), int(eps * 255))\n",
    "    # header3 = \"** LR Config: Init: {} | Peak: {} | Warmup Epoch: {} | Rise: {} | Decay {} | train params {} | all params {} **\".format([float(f'{sch.get_last_lr()[0]:.6f}') for sch in lr_schedulers], [float(f'{v:.6f}') for v in wp_lr], warmups, power, decay_rate, pytorch_train_params, pytorch_total_params)\n",
    "    maxlen  = len(header1)\n",
    "    # header1 = \"{}{}{}\".format('*'*((maxlen-len(header1))//2+1), header1, '*'*((maxlen-len(header1))//2+1) )\n",
    "    # header2 = \"{}{}{}\".format('*'*((maxlen-len(header2))//2+1), header2, '*'*((maxlen-len(header2))//2+1) )\n",
    "    # header3 = \"{}{}{}\".format('*'*((maxlen-len(header3))//2+1), header3, '*'*((maxlen-len(header3))//2+1) )\n",
    "    # maxlen  = max(len(header1), len(header2), len(header3))\n",
    "    print(\"\\n\\n\\n{}\\n{}\\n{}\\n{}\\n\\n\".format(\"*\"*maxlen, header1, header2, \"*\"*maxlen), file=open(logfile, 'a+'))\n",
    "    print(\"Experiment started ...\\n   logging outputs to: \", logfile)\n",
    "    \n",
    "    mAP.reset_global()\n",
    "    mAP_adv.reset_global()\n",
    "    \n",
    "    mAPi.reset_global()\n",
    "    mAPv.reset_global()\n",
    "    mAPt.reset_global()\n",
    "    \n",
    "    mAPi_adv.reset_global()\n",
    "    mAPv_adv.reset_global()\n",
    "    mAPt_adv.reset_global()\n",
    "    \n",
    "    psnr_values_list = []\n",
    "    ssim_values_list = []\n",
    "    lpips_values_list = []\n",
    "    lpips = piq.LPIPS()\n",
    "    \n",
    "    for test_dataloader in test_dataloaders:\n",
    "        # index = 1\n",
    "        test_adv(test_dataloader, model, activation, final_eval=True)\n",
    "        \n",
    "        # break\n",
    "        ###### Normal ######\n",
    "        print(\"Done...!. Printing Stats.\")\n",
    "    \n",
    "    if set_chlg_eval:\n",
    "        mAP_i = mAP.compute_video_AP('i', ignore_null=set_chlg_eval)\n",
    "        mAP_v = mAP.compute_video_AP('v', ignore_null=set_chlg_eval)\n",
    "        mAP_t = mAP.compute_video_AP('t', ignore_null=set_chlg_eval)\n",
    "    else:\n",
    "        mAP_i = mAPi.compute_video_AP(ignore_null=set_chlg_eval)\n",
    "        mAP_v = mAPv.compute_video_AP(ignore_null=set_chlg_eval)\n",
    "        mAP_t = mAPt.compute_video_AP(ignore_null=set_chlg_eval)\n",
    "    \n",
    "    mAP_iv = mAP.compute_video_AP('iv', ignore_null=set_chlg_eval)\n",
    "    mAP_it = mAP.compute_video_AP('it', ignore_null=set_chlg_eval)\n",
    "    mAP_ivt = mAP.compute_video_AP('ivt', ignore_null=set_chlg_eval) \n",
    "    \n",
    "    ####### Adversarial Metrics #####\n",
    "    \n",
    "    if set_chlg_eval:\n",
    "        mAP_i_adv = mAP_adv.compute_video_AP('i', ignore_null=set_chlg_eval)\n",
    "        mAP_v_adv = mAP_adv.compute_video_AP('v', ignore_null=set_chlg_eval)\n",
    "        mAP_t_adv = mAP_adv.compute_video_AP('t', ignore_null=set_chlg_eval)\n",
    "    else:\n",
    "        mAP_i_adv = mAPi_adv.compute_video_AP(ignore_null=set_chlg_eval)\n",
    "        mAP_v_adv = mAPv_adv.compute_video_AP(ignore_null=set_chlg_eval)\n",
    "        mAP_t_adv = mAPt_adv.compute_video_AP(ignore_null=set_chlg_eval)\n",
    "    \n",
    "    mAP_iv_adv = mAP_adv.compute_video_AP('iv', ignore_null=set_chlg_eval)\n",
    "    mAP_it_adv = mAP_adv.compute_video_AP('it', ignore_null=set_chlg_eval)\n",
    "    mAP_ivt_adv = mAP_adv.compute_video_AP('ivt', ignore_null=set_chlg_eval) \n",
    "    \n",
    "    print('-'*50, file=open(logfile, 'a+'))\n",
    "    print('Test Results\\nPer-category AP: ', file=open(logfile, 'a+'))\n",
    "    # print(f'I   : {mAP_i[\"AP\"]}', file=open(logfile, 'a+'))\n",
    "    # print(f'V   : {mAP_v[\"AP\"]}', file=open(logfile, 'a+'))\n",
    "    # print(f'T   : {mAP_t[\"AP\"]}', file=open(logfile, 'a+'))\n",
    "    # print(f'IV  : {mAP_iv[\"AP\"]}', file=open(logfile, 'a+'))\n",
    "    # print(f'IT  : {mAP_it[\"AP\"]}', file=open(logfile, 'a+'))\n",
    "    # print(f'IVT : {mAP_ivt[\"AP\"]}', file=open(logfile, 'a+'))\n",
    "    print('-'*50, file=open(logfile, 'a+'))\n",
    "    print(f'Mean AP:  I  |  V  |  T  |  IV  |  IT  |  IVT ', file=open(logfile, 'a+'))\n",
    "    print(f':::::: : {mAP_i[\"mAP\"]:.4f} | {mAP_v[\"mAP\"]:.4f} | {mAP_t[\"mAP\"]:.4f} | {mAP_iv[\"mAP\"]:.4f} | {mAP_it[\"mAP\"]:.4f} | {mAP_ivt[\"mAP\"]:.4f} ', file=open(logfile, 'a+'))\n",
    "    print('='*50, file=open(logfile, 'a+'))\n",
    "    print(\"Test results saved @ \", logfile)\n",
    "    \n",
    "    \n",
    "    print('-'*50, file=open(logfile, 'a+'))\n",
    "    print('Adversarial Test Results: ', file=open(logfile, 'a+'))\n",
    "    # print(f'I   : {mAP_i_adv[\"AP\"]}', file=open(logfile, 'a+'))\n",
    "    # print(f'V   : {mAP_v_adv[\"AP\"]}projected_gradient_descent', file=open(logfile, 'a+'))\n",
    "    # print(f'T   : {mAP_t_adv[\"AP\"]}', file=open(logfile, 'a+'))\n",
    "    # print(f'IV  : {mAP_iv_adv[\"AP\"]}', file=open(logfile, 'a+'))\n",
    "    # print(f'IT  : {mAP_it_adv[\"AP\"]}', file=open(logfile, 'a+'))\n",
    "    # print(f'IVT : {mAP_ivt_adv[\"AP\"]}', file=open(logfile, 'a+'))\n",
    "    print('-'*50, file=open(logfile, 'a+'))\n",
    "    print(f'Mean AP:  I  |  V  |  T  |  IV  |  IT  |  IVT ', file=open(logfile, 'a+'))\n",
    "    print(f':::::: : {mAP_i_adv[\"mAP\"]:.4f} | {mAP_v_adv[\"mAP\"]:.4f} | {mAP_t_adv[\"mAP\"]:.4f} | {mAP_iv_adv[\"mAP\"]:.4f} | {mAP_it_adv[\"mAP\"]:.4f} | {mAP_ivt_adv[\"mAP\"]:.4f} ', file=open(logfile, 'a+'))\n",
    "    print('='*50, file=open(logfile, 'a+'))\n",
    "    print('-'*50, file=open(logfile, 'a+'))\n",
    "    print(f'PSNR: {np.mean(psnr_values_list):.4f}    | SSIM: {np.mean(ssim_values_list):.4f}     | LPIPS: {1 - np.mean(lpips_values_list):.4f}', file=open(logfile, 'a+'))\n",
    "    print('-'*50, file=open(logfile, 'a+'))\n",
    "    print(\"Test results saved @ \", logfile)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d945b5d9-1599-4d2f-8592-41c730facf46",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4cbe3ef-1c80-4bf4-b4f3-7f647da96fb4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ca5b7a3-ae77-4288-b3de-83d8076b1cfc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
